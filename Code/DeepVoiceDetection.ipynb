{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we will import all data here and launch all functionality\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458555</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>3001.354791</td>\n",
       "      <td>3344.517129</td>\n",
       "      <td>5534.632735</td>\n",
       "      <td>0.078978</td>\n",
       "      <td>-359.40960</td>\n",
       "      <td>137.64343</td>\n",
       "      <td>-37.699123</td>\n",
       "      <td>6.325547</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.760785</td>\n",
       "      <td>-6.768481</td>\n",
       "      <td>-3.511393</td>\n",
       "      <td>-3.748340</td>\n",
       "      <td>-3.967702</td>\n",
       "      <td>-10.396973</td>\n",
       "      <td>-2.482264</td>\n",
       "      <td>-6.162936</td>\n",
       "      <td>-4.923035</td>\n",
       "      <td>-11.189392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464076</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>2727.966517</td>\n",
       "      <td>3355.361293</td>\n",
       "      <td>5111.337925</td>\n",
       "      <td>0.064329</td>\n",
       "      <td>-390.26126</td>\n",
       "      <td>141.90009</td>\n",
       "      <td>-27.839031</td>\n",
       "      <td>9.437146</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.102802</td>\n",
       "      <td>-6.653375</td>\n",
       "      <td>-3.374868</td>\n",
       "      <td>-3.704915</td>\n",
       "      <td>-2.511039</td>\n",
       "      <td>-9.781481</td>\n",
       "      <td>-2.933311</td>\n",
       "      <td>-6.106406</td>\n",
       "      <td>-4.896005</td>\n",
       "      <td>-11.024654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484786</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>3107.355612</td>\n",
       "      <td>3969.098026</td>\n",
       "      <td>6465.931280</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>-456.10266</td>\n",
       "      <td>133.50476</td>\n",
       "      <td>-11.117912</td>\n",
       "      <td>14.982422</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.706840</td>\n",
       "      <td>-6.763403</td>\n",
       "      <td>-3.531775</td>\n",
       "      <td>-3.923490</td>\n",
       "      <td>-2.337104</td>\n",
       "      <td>-8.130886</td>\n",
       "      <td>-2.786967</td>\n",
       "      <td>-5.898662</td>\n",
       "      <td>-4.085208</td>\n",
       "      <td>-9.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478862</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>3312.825733</td>\n",
       "      <td>4015.887142</td>\n",
       "      <td>6800.919974</td>\n",
       "      <td>0.075007</td>\n",
       "      <td>-455.28723</td>\n",
       "      <td>128.96028</td>\n",
       "      <td>-13.122722</td>\n",
       "      <td>23.113510</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.924266</td>\n",
       "      <td>-7.216356</td>\n",
       "      <td>-5.256391</td>\n",
       "      <td>-5.810167</td>\n",
       "      <td>-3.952243</td>\n",
       "      <td>-9.662618</td>\n",
       "      <td>-2.115171</td>\n",
       "      <td>-5.361967</td>\n",
       "      <td>-1.982848</td>\n",
       "      <td>-9.893876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449824</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>3138.301541</td>\n",
       "      <td>3554.610188</td>\n",
       "      <td>5831.376262</td>\n",
       "      <td>0.080952</td>\n",
       "      <td>-409.34323</td>\n",
       "      <td>127.41835</td>\n",
       "      <td>-12.608589</td>\n",
       "      <td>29.327412</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.284443</td>\n",
       "      <td>-9.627606</td>\n",
       "      <td>-5.086654</td>\n",
       "      <td>-5.323502</td>\n",
       "      <td>-6.410156</td>\n",
       "      <td>-9.247939</td>\n",
       "      <td>-3.309547</td>\n",
       "      <td>-3.999227</td>\n",
       "      <td>-2.692699</td>\n",
       "      <td>-10.764003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>0.409185</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>2614.758586</td>\n",
       "      <td>2886.698400</td>\n",
       "      <td>5214.357565</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>-328.55112</td>\n",
       "      <td>141.53745</td>\n",
       "      <td>-22.659441</td>\n",
       "      <td>13.024714</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.717110</td>\n",
       "      <td>-1.697525</td>\n",
       "      <td>-3.740438</td>\n",
       "      <td>-3.175358</td>\n",
       "      <td>-0.975767</td>\n",
       "      <td>-0.465912</td>\n",
       "      <td>-2.515925</td>\n",
       "      <td>-2.404339</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>-4.774403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>0.390581</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>2457.173609</td>\n",
       "      <td>2869.278324</td>\n",
       "      <td>4877.645216</td>\n",
       "      <td>0.057779</td>\n",
       "      <td>-326.41880</td>\n",
       "      <td>145.77818</td>\n",
       "      <td>-25.167551</td>\n",
       "      <td>8.504569</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.317368</td>\n",
       "      <td>-1.120305</td>\n",
       "      <td>-3.904533</td>\n",
       "      <td>-2.995485</td>\n",
       "      <td>-0.848178</td>\n",
       "      <td>-0.912807</td>\n",
       "      <td>-3.697724</td>\n",
       "      <td>-2.362756</td>\n",
       "      <td>0.633791</td>\n",
       "      <td>-3.956865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.388144</td>\n",
       "      <td>0.068845</td>\n",
       "      <td>2258.660148</td>\n",
       "      <td>2789.668381</td>\n",
       "      <td>4219.333728</td>\n",
       "      <td>0.052754</td>\n",
       "      <td>-329.84766</td>\n",
       "      <td>153.84966</td>\n",
       "      <td>-26.846690</td>\n",
       "      <td>-1.657135</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.487367</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>-3.089279</td>\n",
       "      <td>-1.760390</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>-1.194933</td>\n",
       "      <td>-4.528350</td>\n",
       "      <td>-3.063631</td>\n",
       "      <td>-0.315218</td>\n",
       "      <td>-3.612579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.400583</td>\n",
       "      <td>0.064557</td>\n",
       "      <td>2303.049530</td>\n",
       "      <td>2882.060450</td>\n",
       "      <td>4471.237232</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>-341.36500</td>\n",
       "      <td>151.41124</td>\n",
       "      <td>-19.925772</td>\n",
       "      <td>0.934836</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.056502</td>\n",
       "      <td>0.127086</td>\n",
       "      <td>-3.819226</td>\n",
       "      <td>-2.195555</td>\n",
       "      <td>0.904972</td>\n",
       "      <td>-0.282693</td>\n",
       "      <td>-3.279342</td>\n",
       "      <td>-2.018431</td>\n",
       "      <td>-0.554217</td>\n",
       "      <td>-4.517551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>0.408893</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>2486.869372</td>\n",
       "      <td>3040.300261</td>\n",
       "      <td>5244.259240</td>\n",
       "      <td>0.055984</td>\n",
       "      <td>-346.30496</td>\n",
       "      <td>148.96796</td>\n",
       "      <td>-13.712780</td>\n",
       "      <td>5.987595</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.148685</td>\n",
       "      <td>-0.117924</td>\n",
       "      <td>-3.310311</td>\n",
       "      <td>-2.499541</td>\n",
       "      <td>0.743234</td>\n",
       "      <td>-0.463106</td>\n",
       "      <td>-2.182137</td>\n",
       "      <td>-0.949366</td>\n",
       "      <td>-0.470563</td>\n",
       "      <td>-4.808112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5912 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n",
       "0        0.458555  0.019645        3001.354791         3344.517129   \n",
       "1        0.464076  0.014318        2727.966517         3355.361293   \n",
       "2        0.484786  0.009045        3107.355612         3969.098026   \n",
       "3        0.478862  0.009569        3312.825733         4015.887142   \n",
       "4        0.449824  0.014388        3138.301541         3554.610188   \n",
       "...           ...       ...                ...                 ...   \n",
       "5907     0.409185  0.067176        2614.758586         2886.698400   \n",
       "5908     0.390581  0.073916        2457.173609         2869.278324   \n",
       "5909     0.388144  0.068845        2258.660148         2789.668381   \n",
       "5910     0.400583  0.064557        2303.049530         2882.060450   \n",
       "5911     0.408893  0.068255        2486.869372         3040.300261   \n",
       "\n",
       "          rolloff  zero_crossing_rate      mfcc1      mfcc2      mfcc3  \\\n",
       "0     5534.632735            0.078978 -359.40960  137.64343 -37.699123   \n",
       "1     5111.337925            0.064329 -390.26126  141.90009 -27.839031   \n",
       "2     6465.931280            0.065080 -456.10266  133.50476 -11.117912   \n",
       "3     6800.919974            0.075007 -455.28723  128.96028 -13.122722   \n",
       "4     5831.376262            0.080952 -409.34323  127.41835 -12.608589   \n",
       "...           ...                 ...        ...        ...        ...   \n",
       "5907  5214.357565            0.065293 -328.55112  141.53745 -22.659441   \n",
       "5908  4877.645216            0.057779 -326.41880  145.77818 -25.167551   \n",
       "5909  4219.333728            0.052754 -329.84766  153.84966 -26.846690   \n",
       "5910  4471.237232            0.052277 -341.36500  151.41124 -19.925772   \n",
       "5911  5244.259240            0.055984 -346.30496  148.96796 -13.712780   \n",
       "\n",
       "          mfcc4  ...     mfcc11    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0      6.325547  ...  -9.760785 -6.768481 -3.511393 -3.748340 -3.967702   \n",
       "1      9.437146  ... -10.102802 -6.653375 -3.374868 -3.704915 -2.511039   \n",
       "2     14.982422  ... -10.706840 -6.763403 -3.531775 -3.923490 -2.337104   \n",
       "3     23.113510  ... -10.924266 -7.216356 -5.256391 -5.810167 -3.952243   \n",
       "4     29.327412  ... -13.284443 -9.627606 -5.086654 -5.323502 -6.410156   \n",
       "...         ...  ...        ...       ...       ...       ...       ...   \n",
       "5907  13.024714  ...  -6.717110 -1.697525 -3.740438 -3.175358 -0.975767   \n",
       "5908   8.504569  ...  -5.317368 -1.120305 -3.904533 -2.995485 -0.848178   \n",
       "5909  -1.657135  ...  -4.487367  0.013983 -3.089279 -1.760390  0.131551   \n",
       "5910   0.934836  ...  -5.056502  0.127086 -3.819226 -2.195555  0.904972   \n",
       "5911   5.987595  ...  -6.148685 -0.117924 -3.310311 -2.499541  0.743234   \n",
       "\n",
       "         mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  \n",
       "0    -10.396973 -2.482264 -6.162936 -4.923035 -11.189392  \n",
       "1     -9.781481 -2.933311 -6.106406 -4.896005 -11.024654  \n",
       "2     -8.130886 -2.786967 -5.898662 -4.085208  -9.087442  \n",
       "3     -9.662618 -2.115171 -5.361967 -1.982848  -9.893876  \n",
       "4     -9.247939 -3.309547 -3.999227 -2.692699 -10.764003  \n",
       "...         ...       ...       ...       ...        ...  \n",
       "5907  -0.465912 -2.515925 -2.404339  0.966102  -4.774403  \n",
       "5908  -0.912807 -3.697724 -2.362756  0.633791  -3.956865  \n",
       "5909  -1.194933 -4.528350 -3.063631 -0.315218  -3.612579  \n",
       "5910  -0.282693 -3.279342 -2.018431 -0.554217  -4.517551  \n",
       "5911  -0.463106 -2.182137 -0.949366 -0.470563  -4.808112  \n",
       "\n",
       "[5912 rows x 26 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert balanced csv into dataframe and seperate labels\n",
    "DATASET_PATH = \"/Users/connormaclachlan/Desktop/CS433_Project/Code/audio_features5.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "data = df.iloc[:,:-1]\n",
    "labels = df.iloc[:,-1]\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "labels = labels.ravel()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into tensorflow dataset\n",
    "def convertToDataset(data, labels):\n",
    "    return tf.data.Dataset.zip(tf.data.Dataset.from_tensor_slices(data), tf.data.Dataset.from_tensor_slices(labels))\n",
    "\n",
    "# Process dataset\n",
    "def processData(data, labels):\n",
    "    data = tf.abs(data)\n",
    "    data = tf.expand_dims(data, axis=1)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.1, random_state=42)\n",
    "\n",
    "trainDataset = convertToDataset(X_train, y_train)\n",
    "testDataset = convertToDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.34771500e-01,  2.88258340e-02,  2.95657240e+03,  3.12244336e+03,\n",
       "         5.69613706e+03,  7.52296692e-02, -3.32747860e+02,  1.42060130e+02,\n",
       "        -5.10173840e+01,  2.65516720e+01, -2.30403400e+01,  1.31221510e+01,\n",
       "        -4.83686160e+00, -1.63952080e+01, -5.59854100e+00, -1.61675110e+01,\n",
       "        -1.58248260e+00, -1.81260410e+01, -1.98251720e+00, -2.50885060e+00,\n",
       "        -8.38363600e+00, -1.18850960e+00, -7.47049760e+00,  3.05572150e-01,\n",
       "        -5.17679900e+00, -4.52124500e+00]),\n",
       " 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4138, 26)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "epochs = 100\n",
    "batch = 32\n",
    "prefetch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "trainDataset = trainDataset.map(processData)\n",
    "trainDataset = trainDataset.cache()\n",
    "trainDataset = trainDataset.batch(batch)\n",
    "trainDataset = trainDataset.prefetch(prefetch)\n",
    "\n",
    "testDataset = testDataset.map(processData)\n",
    "testDataset = testDataset.cache()\n",
    "testDataset = testDataset.batch(batch)\n",
    "testDataset = testDataset.prefetch(prefetch)\n",
    "\n",
    "X_val = abs(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 [==============================] - 3s 5ms/step - loss: 8.9972 - accuracy: 0.7687\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.9021\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.9041\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.9053\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2995 - accuracy: 0.9065\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 3.3160 - accuracy: 0.7869\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0765 - accuracy: 0.8347\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6501 - accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.8729\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7904 - accuracy: 0.8729\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5935 - accuracy: 0.8842\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.8879 - accuracy: 0.8639\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7519 - accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.8927\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5672 - accuracy: 0.8934\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.8855\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.9055\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8992\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8987\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.9065\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.9089\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.9084\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.9147\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.9077\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.9161\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.9147\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.9210\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9236\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9328\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9306\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.9261\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.9335\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9348\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9372\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9386\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9439\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9459\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9348\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9352\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9427\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9478\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9464\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9505\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9495\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9488\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9548\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9572\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9531\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9555\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9509\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9570\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9538\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9526\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9551\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9538\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9565\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9584\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9555\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9601\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9582\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9580\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9623\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9584\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9623\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9519\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9294\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9570\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9613\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9623\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9642\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9625\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9623\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9640\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9654\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9650\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9657\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9659\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9650\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9628\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9645\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9669\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9640\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9669\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9671\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9652\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9633\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9671\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9671\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9674\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9674\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9674\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9674\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9671\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9621\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9655\n",
      "Test Accuracy: 0.9655388593673706\n",
      "Test Loss: 0.1129143089056015\n"
     ]
    }
   ],
   "source": [
    "# Define the NN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(26,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainDataset, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(testDataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fd7bb7b9700>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzvElEQVR4nO3de1RVdf7/8dcBBLxwERvBk6g0mpfJtLQYsotOlJfGNO3r2JeKHNMZE0tNU1d5TWWyMsNMykpzfjpdpuSrNtnXtLxMZInRdDFKQyUNrC8hgnE7Z//+ME+d0OKwDxzO2c/HWnutzmff3sdYvHl/Pp+9PzbDMAwBAICAFeTrAAAAQMMi2QMAEOBI9gAABDiSPQAAAY5kDwBAgCPZAwAQ4Ej2AAAEuBBfB2CG0+nUsWPHFBERIZvN5utwAAAeMgxDJ0+elN1uV1BQw9WfFRUVqqqqMn2d0NBQhYeHeyGixuXXyf7YsWOKj4/3dRgAAJMKCgrUvn37Brl2RUWFEjq2UuFxh+lrxcXFKT8/3+8Svl8n+4iICEnS4X2dFNmKEQkEppsu7OnrEIAGU6Nq7da/XL/PG0JVVZUKjzt0OKeTIiPqnytKTzrVsc8hVVVVkewb05mu+8hWQab+BwJNWYitma9DABrODy9sb4yh2FYRNrWKqP99nPLf4WK/TvYAANSVw3DKYWI1GIfh9F4wjYxkDwCwBKcMOVX/bG/mXF+j7xsAgABHZQ8AsASnnDLTEW/ubN8i2QMALMFhGHIY9e+KN3Our9GNDwBAgKOyBwBYgpUn6JHsAQCW4JQhh0WTPd34AAAEOCp7AIAl0I0PAECAYzY+AAAIWFT2AABLcP6wmTnfX5HsAQCW4DA5G9/Mub5GsgcAWILDkMlV77wXS2NjzB4AgABHZQ8AsATG7AEACHBO2eSQzdT5/opufAAAGsDOnTs1dOhQ2e122Ww2ZWVlnfPYv/71r7LZbFq2bJlbe3FxsVJSUhQZGano6GiNHTtWZWVlHsdCsgcAWILTML95ory8XL169dKKFSt+8bgNGzbo3Xffld1ur7UvJSVFn3zyibZu3arNmzdr586dGj9+vGeBiG58AIBFOEx243t67uDBgzV48OBfPObo0aOaNGmS3njjDd1www1u+/bv368tW7bo/fffV9++fSVJy5cv15AhQ/TII4+c9Y+Dc6GyBwDAA6WlpW5bZWVlva7jdDp12223afr06frd735Xa392draio6NdiV6SkpOTFRQUpD179nh0L5I9AMASzlT2ZjZJio+PV1RUlGtLT0+vVzwPPfSQQkJCdPfdd591f2Fhodq2bevWFhISopiYGBUWFnp0L7rxAQCW4DRschomZuP/cG5BQYEiIyNd7WFhYR5fKycnR48//rj27dsnm63hZ/lT2QMA4IHIyEi3rT7JfteuXTp+/Lg6dOigkJAQhYSE6PDhw7r33nvVqVMnSVJcXJyOHz/udl5NTY2Ki4sVFxfn0f2o7AEAltDYE/R+yW233abk5GS3toEDB+q2227TmDFjJElJSUkqKSlRTk6O+vTpI0navn27nE6nEhMTPbofyR4AYAkOBclhokPb4eHxZWVlOnDggOtzfn6+cnNzFRMTow4dOqhNmzZuxzdr1kxxcXHq2rWrJKl79+4aNGiQxo0bp8zMTFVXVystLU2jR4/2aCa+RLIHAFiEYXLM3vDw3L1792rAgAGuz1OnTpUkpaamas2aNXW6xrp165SWlqZrr71WQUFBGjlypDIyMjyKQyLZAwDQIPr37y/DqPubeA4dOlSrLSYmRuvXrzcdC8keAGAJTWnMvrGR7AEAluAwguQwTIzZs549AABoqqjsAQCW4JRNThM1rlP+W9qT7AEAlmDlMXu68QEACHBU9gAASzA/QY9ufAAAmrTTY/YmFsKhGx8AADRVVPYAAEtwmnw3PrPxAQBo4hizBwAgwDkVZNnn7BmzBwAgwFHZAwAswWHY5DCxxK2Zc32NZA8AsASHyQl6DrrxAQBAU0VlDwCwBKcRJKeJ2fhOZuMDANC00Y0PAAACFpU9AMASnDI3o97pvVAaHckeAGAJ5l+q47+d4f4bOQAAqBMqewCAJZh/N77/1sckewCAJVh5PXuSPQDAEqxc2ftv5AAAoE6o7AEAlmD+pTr+Wx+T7AEAluA0bHKaec7ej1e9898/UwAAQJ1Q2QMALMFpshvfn1+qQ7IHAFiC+VXv/DfZ+2/kAACgTqjsAQCW4JBNDhMvxjFzrq+R7AEAlkA3PgAACFhU9gAAS3DIXFe8w3uhNDqSPQDAEqzcjU+yBwBYAgvhAAAAr9q5c6eGDh0qu90um82mrKws177q6mrNmDFDPXv2VMuWLWW323X77bfr2LFjbtcoLi5WSkqKIiMjFR0drbFjx6qsrMzjWEj2AABLMH5Yz76+m+HheH95ebl69eqlFStW1Np36tQp7du3T7Nnz9a+ffv06quvKi8vTzfeeKPbcSkpKfrkk0+0detWbd68WTt37tT48eM9/u504wMALKGxu/EHDx6swYMHn3VfVFSUtm7d6tb2xBNP6PLLL9eRI0fUoUMH7d+/X1u2bNH777+vvn37SpKWL1+uIUOG6JFHHpHdbq9zLFT2AAB4oLS01G2rrKz0ynVPnDghm82m6OhoSVJ2draio6NdiV6SkpOTFRQUpD179nh0bZI9AMASzixxa2aTpPj4eEVFRbm29PR007FVVFRoxowZuuWWWxQZGSlJKiwsVNu2bd2OCwkJUUxMjAoLCz26Pt34AABLcJhc9e7MuQUFBa6ELElhYWGm4qqurtaoUaNkGIZWrlxp6lrnQrIHAMADkZGRbsnejDOJ/vDhw9q+fbvbdePi4nT8+HG342tqalRcXKy4uDiP7kM3PgDAErzVje8tZxL9F198oTfffFNt2rRx25+UlKSSkhLl5OS42rZv3y6n06nExESP7kVlDwCwBKeC5DRR43p6bllZmQ4cOOD6nJ+fr9zcXMXExKhdu3a6+eabtW/fPm3evFkOh8M1Dh8TE6PQ0FB1795dgwYN0rhx45SZmanq6mqlpaVp9OjRHs3El0j2AAA0iL1792rAgAGuz1OnTpUkpaamat68edq4caMkqXfv3m7nvfXWW+rfv78kad26dUpLS9O1116roKAgjRw5UhkZGR7HQrIHAFiCw7DJYaIr3tNz+/fvL8Mwzrn/l/adERMTo/Xr13t037Mh2QMALMHsuLu3x+wbE8keAGAJhslV7wwWwgEAAE0VlT0AwBIcssnh4WI2Pz/fX5HsAQCW4DTMjbs7f30+XZNFNz4AAAGOyh766N2WevnJtvrioxYqLmqmuc/m64rBJ1z7H5ncQVtfinE7p0//Ui1e/6Xrc+l3wXrygfO1Z2uUbEHSlUNKNOHBo2re0tlo3wMwa+gd3+rmCccV85safflpcz35wPnKy23h67DgJU6TE/TMnOtrJHuo4lSQLvjd9xp4S7EWjE046zF9B5Tq3seOuD43C3Xvz3ooraOKi5op/YWDqqm26dGpHbRserxmPXm4QWMHvOWaG7/T+LnHtHxme322r4VuGveNFq3/UmOv6qoT/9fM1+HBC5yyyWli3N3Mub7WJP5MWbFihTp16qTw8HAlJibqvffe83VIlnLZH07qjhmF6veTav7nmoUaimlb49oioh2ufUe+CNPetyI15dEj6nbpKV2UWK67Fn6lHf8Trf8r5O9J+IcR47/VlvUx+t8XY3Tki3BlzGivyu9tGnhLsa9DA0zzebJ/8cUXNXXqVM2dO1f79u1Tr169NHDgwFor/cC3/pPdSqN6/k5jr+ymjJntVVoc7Nq3f29LtYqq0YW9vne1XXrVSdmCpM8+aOmLcAGPhDRzqsvFp7RvV4SrzTBs+mBXhHr0OeXDyOBNZ96gZ2bzVz5P9kuXLtW4ceM0ZswY9ejRQ5mZmWrRooWee+45X4eGH/TtX6rpjx/WQy8d1Nj7v9ZH2a10/60XyPFDcV/8TYii29S4nRMcIkVE16j4OJU9mr7IGIeCQ6SSb9x/Xr/7NkStf1NzjrPgb86M2ZvZ/JVPfxNXVVUpJydHs2bNcrUFBQUpOTlZ2dnZtY6vrKxUZWWl63NpaWmjxGl1/YeXuP47oXuFEnp8rzuSeug/77TSJVeV+S4wAECd+PTPlG+//VYOh0OxsbFu7bGxsa6l/n4qPT1dUVFRri0+Pr6xQsVPtOtYpaiYGh07FCZJivlNjUr+z/3vRkeNdLIkRDFtqYrQ9JUWB8tRI0X/rIpvfV6NvvuG3qlA4ZTJ9eyZoNc4Zs2apRMnTri2goICX4dkSd8ca6bS74IV07ZaktS9b7nKToToi/80dx2TuztChlPqdkm5r8IE6qymOkhf/KeFLrnypKvNZjPU+8oyfZrDo3eBwvhhNn59N8OPk71P/2Q977zzFBwcrKKiIrf2oqIixcXF1To+LCxMYWFhjRWeZXxfHqRj+T/+uxYWhOrgx80VEV2jiNYO/b9H43TlDSVq3bZGXx8K1TML7bInVKpP/9O/GDt0qVTfAaVaNi1ekx76So5qm1Y8cL6uGVaiNnFU9vAPrz59nqYtK9DnH7ZQ3genH70Lb+HU/74Q8+snwy+w6p2PhIaGqk+fPtq2bZuGDx8uSXI6ndq2bZvS0tJ8GZqlfP5hC913c2fX56fmnS9Jum5UsSalFyh/f7i2vpyg8tJgtYmt0aXXlCr1vkKFhv34rP2MJw5rxf3tNXPUb10v1blr4dFG/y5Afe3Y2FpRbRy6fXqhWv+mRl9+0lz3pySo5FuesYf/8/lg1NSpU5Wamqq+ffvq8ssv17Jly1ReXq4xY8b4OjTL6HVFmd44lnvO/Yv/8eU5950R2drBC3Tg9zauPk8bV5/n6zDQQHiDng/96U9/0jfffKM5c+aosLBQvXv31pYtW2pN2gMAwAy68X0sLS2NbnsAABpIk0j2AAA0NCu/G59kDwCwBCt34/vvbAMAAFAnVPYAAEuwcmVPsgcAWIKVkz3d+AAABDgqewCAJVi5sifZAwAswZC5x+eMXz+kySLZAwAswcqVPWP2AAAEOCp7AIAlWLmyJ9kDACzBysmebnwAAAIclT0AwBKsXNmT7AEAlmAYNhkmEraZc32NbnwAAAIclT0AwBJYzx4AgABn5TF7uvEBAAhwVPYAAEtggh4AAAHuTDe+mc0TO3fu1NChQ2W322Wz2ZSVleW23zAMzZkzR+3atVPz5s2VnJysL774wu2Y4uJipaSkKDIyUtHR0Ro7dqzKyso8/u4kewCAJZyp7M1snigvL1evXr20YsWKs+5fsmSJMjIylJmZqT179qhly5YaOHCgKioqXMekpKTok08+0datW7V582bt3LlT48eP9/i7040PAIAHSktL3T6HhYUpLCys1nGDBw/W4MGDz3oNwzC0bNkyPfDAAxo2bJgkae3atYqNjVVWVpZGjx6t/fv3a8uWLXr//ffVt29fSdLy5cs1ZMgQPfLII7Lb7XWOmcoeAGAJhsku/DOVfXx8vKKiolxbenq6x7Hk5+ersLBQycnJrraoqCglJiYqOztbkpSdna3o6GhXopek5ORkBQUFac+ePR7dj8oeAGAJhiTDMHe+JBUUFCgyMtLVfraq/tcUFhZKkmJjY93aY2NjXfsKCwvVtm1bt/0hISGKiYlxHVNXJHsAADwQGRnpluz9Ad34AABLOPMGPTObt8TFxUmSioqK3NqLiopc++Li4nT8+HG3/TU1NSouLnYdU1ckewCAJTT2bPxfkpCQoLi4OG3bts3VVlpaqj179igpKUmSlJSUpJKSEuXk5LiO2b59u5xOpxITEz26H934AAA0gLKyMh04cMD1OT8/X7m5uYqJiVGHDh00efJkLVy4UF26dFFCQoJmz54tu92u4cOHS5K6d++uQYMGady4ccrMzFR1dbXS0tI0evRoj2biSyR7AIBFOA2bbI34bvy9e/dqwIABrs9Tp06VJKWmpmrNmjW67777VF5ervHjx6ukpERXXnmltmzZovDwcNc569atU1pamq699loFBQVp5MiRysjI8Dh2kj0AwBIMw+RsfA/P7d+/v4xfOMlms2nBggVasGDBOY+JiYnR+vXrPbvxWTBmDwBAgKOyBwBYgpUXwiHZAwAsgWQPAECAa+wJek0JY/YAAAQ4KnsAgCU09mz8poRkDwCwhNPJ3syYvReDaWR04wMAEOCo7AEAlsBsfAAAApyhH9ekr+/5/opufAAAAhyVPQDAEujGBwAg0Fm4H59kDwCwBpOVvfy4smfMHgCAAEdlDwCwBN6gBwBAgLPyBD268QEACHBU9gAAazBs5ibZ+XFlT7IHAFiClcfs6cYHACDAUdkDAKyBl+oAABDYrDwbv07JfuPGjXW+4I033ljvYAAAgPfVKdkPHz68Thez2WxyOBxm4gEAoOH4cVe8GXVK9k6ns6HjAACgQVm5G9/UbPyKigpvxQEAQMMyvLD5KY+TvcPh0IMPPqjzzz9frVq10pdffilJmj17tp599lmvBwgAAMzxONkvWrRIa9as0ZIlSxQaGupqv+iii/TMM894NTgAALzH5oXNP3mc7NeuXaunn35aKSkpCg4OdrX36tVLn332mVeDAwDAa+jGr7ujR4+qc+fOtdqdTqeqq6u9EhQAAPAej5N9jx49tGvXrlrt//znP3XJJZd4JSgAALzOwpW9x2/QmzNnjlJTU3X06FE5nU69+uqrysvL09q1a7V58+aGiBEAAPMsvOqdx5X9sGHDtGnTJr355ptq2bKl5syZo/3792vTpk267rrrGiJGAABgQr3ejX/VVVdp69at3o4FAIAGY+Ulbuu9EM7evXu1f/9+SafH8fv06eO1oAAA8DpWvau7r776Srfccov+/e9/Kzo6WpJUUlKiK664Qi+88ILat2/v7RgBAIAJHo/Z33nnnaqurtb+/ftVXFys4uJi7d+/X06nU3feeWdDxAgAgHlnJuiZ2fyUx8l+x44dWrlypbp27epq69q1q5YvX66dO3d6NTgAALzFZpjfPOFwODR79mwlJCSoefPm+u1vf6sHH3xQxk8G/w3D0Jw5c9SuXTs1b95cycnJ+uKLL7z8zeuR7OPj48/68hyHwyG73e6VoAAA8LpGfs7+oYce0sqVK/XEE09o//79euihh7RkyRItX77cdcySJUuUkZGhzMxM7dmzRy1bttTAgQO9vtCcx8n+4Ycf1qRJk7R3715X2969e3XPPffokUce8WpwAAD4q3feeUfDhg3TDTfcoE6dOunmm2/W9ddfr/fee0/S6ap+2bJleuCBBzRs2DBdfPHFWrt2rY4dO6asrCyvxlKnCXqtW7eWzfbjWEV5ebkSExMVEnL69JqaGoWEhOjPf/6zhg8f7tUAAQDwCi+9VKe0tNStOSwsTGFhYbUOv+KKK/T000/r888/14UXXqgPP/xQu3fv1tKlSyVJ+fn5KiwsVHJysuucqKgoJSYmKjs7W6NHj65/rD9Tp2S/bNkyr90QAACf8NKjd/Hx8W7Nc+fO1bx582odPnPmTJWWlqpbt24KDg6Ww+HQokWLlJKSIkkqLCyUJMXGxrqdFxsb69rnLXVK9qmpqV69KQAA/qqgoECRkZGuz2er6iXppZde0rp167R+/Xr97ne/U25uriZPniy73d7oebXeL9WRpIqKClVVVbm1/fQfAACAJsNLlX1kZGSdct306dM1c+ZMV3d8z549dfjwYaWnpys1NVVxcXGSpKKiIrVr1851XlFRkXr37m0i0No8nqBXXl6utLQ0tW3bVi1btlTr1q3dNgAAmqRGno1/6tQpBQW5p9ng4GA5nU5JUkJCguLi4rRt2zbX/tLSUu3Zs0dJSUkef71f4nGyv++++7R9+3atXLlSYWFheuaZZzR//nzZ7XatXbvWq8EBAOCvhg4dqkWLFum1117ToUOHtGHDBi1dulQ33XSTJMlms2ny5MlauHChNm7cqI8++ki333677Ha71ye7e9yNv2nTJq1du1b9+/fXmDFjdNVVV6lz587q2LGj1q1b55p4AABAk9LIS9wuX75cs2fP1l133aXjx4/LbrfrL3/5i+bMmeM65r777lN5ebnGjx+vkpISXXnlldqyZYvCw8PrH+dZeJzsi4uLdcEFF0g6PW5RXFwsSbryyis1YcIErwYHAIC31OcteD8/3xMRERFatmzZLz7RZrPZtGDBAi1YsKD+gdWBx934F1xwgfLz8yVJ3bp100svvSTpdMV/ZmEcAADQdHic7MeMGaMPP/xQ0ulnCFesWKHw8HBNmTJF06dP93qAAAB4RSNP0GtKPO7GnzJliuu/k5OT9dlnnyknJ0edO3fWxRdf7NXgAACAeaaes5ekjh07qmPHjt6IBQCABmOTyTF7r0XS+OqU7DMyMup8wbvvvrvewQAAAO+rU7J/7LHH6nQxm83mk2R/8+X9FGILbfT7Ao0hqBdLRyNwBTkqpY8a6WaN/OhdU1KnZH9m9j0AAH7LS6/L9Ucez8YHAAD+xfQEPQAA/IKFK3uSPQDAEhr7DXpNCd34AAAEOCp7AIA1WLgbv16V/a5du3TrrbcqKSlJR48elST9/e9/1+7du70aHAAAXmPh1+V6nOxfeeUVDRw4UM2bN9cHH3ygyspKSdKJEye0ePFirwcIAADM8TjZL1y4UJmZmVq1apWaNWvmau/Xr5/27dvn1eAAAPCWMxP0zGz+yuMx+7y8PF199dW12qOiolRSUuKNmAAA8D4Lv0HP48o+Li5OBw4cqNW+e/duXXDBBV4JCgAAr2PMvu7GjRune+65R3v27JHNZtOxY8e0bt06TZs2TRMmTGiIGAEAgAked+PPnDlTTqdT1157rU6dOqWrr75aYWFhmjZtmiZNmtQQMQIAYJqVX6rjcbK32Wy6//77NX36dB04cEBlZWXq0aOHWrVq1RDxAQDgHRZ+zr7eL9UJDQ1Vjx49vBkLAABoAB4n+wEDBshmO/eMxO3bt5sKCACABmH28TkrVfa9e/d2+1xdXa3c3Fx9/PHHSk1N9VZcAAB4F934dffYY4+dtX3evHkqKyszHRAAAPAur616d+utt+q5557z1uUAAPAuCz9n77VV77KzsxUeHu6tywEA4FU8eueBESNGuH02DENff/219u7dq9mzZ3stMAAA4B0eJ/uoqCi3z0FBQeratasWLFig66+/3muBAQAA7/Ao2TscDo0ZM0Y9e/ZU69atGyomAAC8z8Kz8T2aoBccHKzrr7+e1e0AAH7Hykvcejwb/6KLLtKXX37ZELEAAIAG4HGyX7hwoaZNm6bNmzfr66+/VmlpqdsGAECTZcHH7iQPxuwXLFige++9V0OGDJEk3XjjjW6vzTUMQzabTQ6Hw/tRAgBgloXH7Ouc7OfPn6+//vWveuuttxoyHgAA4GV1TvaGcfpPmmuuuabBggEAoKHwUp06+qXV7gAAaNLoxq+bCy+88FcTfnFxsamAAACAd3mU7OfPn1/rDXoAAPgDuvHraPTo0Wrbtm1DxQIAQMPxQTf+0aNHNWPGDL3++us6deqUOnfurNWrV6tv376nL2kYmjt3rlatWqWSkhL169dPK1euVJcuXUwEWludn7NnvB4AgLr77rvv1K9fPzVr1kyvv/66Pv30Uz366KNur5tfsmSJMjIylJmZqT179qhly5YaOHCgKioqvBqLx7PxAQDwS41c2T/00EOKj4/X6tWrXW0JCQk/Xs4wtGzZMj3wwAMaNmyYJGnt2rWKjY1VVlaWRo8ebSJYd3Wu7J1OJ134AAC/5a134//8zbGVlZVnvd/GjRvVt29f/dd//Zfatm2rSy65RKtWrXLtz8/PV2FhoZKTk11tUVFRSkxMVHZ2tle/u8evywUAwC+ZeVXuT3oF4uPjFRUV5drS09PPersvv/zSNf7+xhtvaMKECbr77rv1/PPPS5IKCwslSbGxsW7nxcbGuvZ5i8fr2QMAYGUFBQWKjIx0fQ4LCzvrcU6nU3379tXixYslSZdccok+/vhjZWZmKjU1tVFiPYPKHgBgDV6q7CMjI922cyX7du3aqUePHm5t3bt315EjRyRJcXFxkqSioiK3Y4qKilz7vIVkDwCwhMZez75fv37Ky8tza/v888/VsWNHSacn68XFxWnbtm2u/aWlpdqzZ4+SkpJMf9+fohsfAIAGMGXKFF1xxRVavHixRo0apffee09PP/20nn76aUmnH2mfPHmyFi5cqC5duighIUGzZ8+W3W7X8OHDvRoLyR4AYA2N/OjdZZddpg0bNmjWrFlasGCBEhIStGzZMqWkpLiOue+++1ReXq7x48erpKREV155pbZs2aLw8HATgdZGsgcAWIIvXpf7xz/+UX/84x/PfU2bTQsWLNCCBQvqH1gdMGYPAECAo7IHAFgDS9wCABDgLJzs6cYHACDAUdkDACzB9sNm5nx/RbIHAFiDhbvxSfYAAEvwxaN3TQVj9gAABDgqewCANdCNDwCABfhxwjaDbnwAAAIclT0AwBKsPEGPZA8AsAYLj9nTjQ8AQICjsgcAWALd+AAABDq68QEAQKCisgcAWALd+AAABDoLd+OT7AEA1mDhZM+YPQAAAY7KHgBgCYzZAwAQ6OjGBwAAgYrKHgBgCTbDkM2of3lu5lxfI9kDAKyBbnwAABCoqOwBAJbAbHwAAAId3fgAACBQUdkDACyBbnwAAAKdhbvxSfYAAEuwcmXPmD0AAAGOyh4AYA104wMAEPj8uSveDLrxAQAIcFT2AABrMIzTm5nz/RTJHgBgCczGBwAADeZvf/ubbDabJk+e7GqrqKjQxIkT1aZNG7Vq1UojR45UUVFRg9yfZA8AsAbDC1s9vP/++3rqqad08cUXu7VPmTJFmzZt0ssvv6wdO3bo2LFjGjFiRP1u8itI9gAAS7A5zW+SVFpa6rZVVlae855lZWVKSUnRqlWr1Lp1a1f7iRMn9Oyzz2rp0qX6wx/+oD59+mj16tV655139O6773r9u5PsAQDwQHx8vKKiolxbenr6OY+dOHGibrjhBiUnJ7u15+TkqLq62q29W7du6tChg7Kzs70eMxP08KtWb92j2PNr/+W6eX07Pbmwiw8iAswZNepT9ev3ldq3L1VVVbA+/fQ8PfdcLx09Guk6ZvDgA+rf/7A6d/5OLVrU6OabR6i8PNSHUcM0L71Up6CgQJGRP/6shIWFnfXwF154Qfv27dP7779fa19hYaFCQ0MVHR3t1h4bG6vCwkITQZ4dyR6/6p5Rlyg4+MfPHbuUa/GzH2nXG7/xXVCACT17HtemTZ31+edtFBzs1B13/EeLFr2tv/xliCorT/9aDAtzaO/edtq7t53+/Of/+DhieIO3ZuNHRka6JfuzKSgo0D333KOtW7cqPDy8/jf1Ep924+/cuVNDhw6V3W6XzWZTVlaWL8PBOZR+F6rvvv1xu/yaYh07Eq6P3o/ydWhAvcye3V9vvnmBjhyJUn5+ay1dmqjY2FPq0qXYdUxWVle9/HIPffZZGx9GCq8685y9ma2OcnJydPz4cV166aUKCQlRSEiIduzYoYyMDIWEhCg2NlZVVVUqKSlxO6+oqEhxcXFe/uI+Tvbl5eXq1auXVqxY4csw4IGQZk4NGFqk/301TpLN1+EAXtGiRbUk6eRJuunhHddee60++ugj5ebmura+ffsqJSXF9d/NmjXTtm3bXOfk5eXpyJEjSkpK8no8Pu3GHzx4sAYPHlzn4ysrK91mPZaWljZEWPgFSdf+n1pF1OjNDbG+DgXwCpvN0F/+8oE++eQ8HT4c7etw0IAa86U6ERERuuiii9zaWrZsqTZt2rjax44dq6lTpyomJkaRkZGaNGmSkpKS9Pvf/77+QZ6DX43Zp6ena/78+b4Ow9KuH1GovbtiVPzN2SekAP5m4sQcdepUomnTkn/9YPi3Jrbq3WOPPaagoCCNHDlSlZWVGjhwoJ588knv3uQHfpXsZ82apalTp7o+l5aWKj4+3ocRWUtbe4V6J32nRff08HUogFdMmJCjyy8/qunTr9W337bwdTgIcG+//bbb5/DwcK1YsaJRhrL9KtmHhYWd8xEHNLzrbirUieJQvbeDCUvwd4YmTNinK674SjNm/EFFRa18HRAagZXfje9XyR6+Y7MZuu6mIr2ZFSung4l58G8TJ+aof//DWrDgKn3/fYhat/5eklRe3kxVVad/LbZu/b1at66Q3V4mSerUqUTff99Mx4+3UFkZRYdfYtU74Jf1TvpObe2V2voqE/Pg//74xwOSpCVLtru1P/ro5XrzzQskSUOGHNCtt37i2vfII9trHQP4C58m+7KyMh04cMD1OT8/X7m5uYqJiVGHDh18GBl+7oN3YjSkx9W+DgPwisGDR//qMevW9dS6dT0bIRo0FrrxfWTv3r0aMGCA6/OZyXepqalas2aNj6ICAASkJjYbvzH5NNn3799fhh+PgQAA4A8YswcAWALd+AAABDqncXozc76fItkDAKzBwmP2Pl0IBwAANDwqewCAJdhkcszea5E0PpI9AMAaLPwGPbrxAQAIcFT2AABL4NE7AAACHbPxAQBAoKKyBwBYgs0wZDMxyc7Mub5GsgcAWIPzh83M+X6KbnwAAAIclT0AwBLoxgcAINBZeDY+yR4AYA28QQ8AAAQqKnsAgCXwBj0AAAId3fgAACBQUdkDACzB5jy9mTnfX5HsAQDWQDc+AAAIVFT2AABr4KU6AAAENiu/LpdufAAAAhyVPQDAGiw8QY9kDwCwBkPm1qT331xPsgcAWANj9gAAIGBR2QMArMGQyTF7r0XS6Ej2AABrsPAEPbrxAQBoAOnp6brssssUERGhtm3bavjw4crLy3M7pqKiQhMnTlSbNm3UqlUrjRw5UkVFRV6PhWQPALAGpxc2D+zYsUMTJ07Uu+++q61bt6q6ulrXX3+9ysvLXcdMmTJFmzZt0ssvv6wdO3bo2LFjGjFihMkvWhvd+AAAS/DWbPzS0lK39rCwMIWFhdU6fsuWLW6f16xZo7Zt2yonJ0dXX321Tpw4oWeffVbr16/XH/7wB0nS6tWr1b17d7377rv6/e9/X+9Yf47KHgAAD8THxysqKsq1paen1+m8EydOSJJiYmIkSTk5OaqurlZycrLrmG7duqlDhw7Kzs72asxU9gAAa/DSBL2CggJFRka6ms9W1f+c0+nU5MmT1a9fP1100UWSpMLCQoWGhio6Otrt2NjYWBUWFtY/zrMg2QMArMFLyT4yMtIt2dfFxIkT9fHHH2v37t31v78JdOMDANCA0tLStHnzZr311ltq3769qz0uLk5VVVUqKSlxO76oqEhxcXFejYFkDwCwhjOVvZnNo9sZSktL04YNG7R9+3YlJCS47e/Tp4+aNWumbdu2udry8vJ05MgRJSUleeUrn0E3PgDAGpySbCbP98DEiRO1fv16/c///I8iIiJc4/BRUVFq3ry5oqKiNHbsWE2dOlUxMTGKjIzUpEmTlJSU5NWZ+BLJHgBgEY29EM7KlSslSf3793drX716te644w5J0mOPPaagoCCNHDlSlZWVGjhwoJ588sl6x3guJHsAABqAUYc/DsLDw7VixQqtWLGiQWMh2QMArMHC78Yn2QMArMFpSDYTCdvpv8me2fgAAAQ4KnsAgDXQjQ8AQKAzmezlv8mebnwAAAIclT0AwBroxgcAIMA5DZnqimc2PgAAaKqo7AEA1mA4T29mzvdTJHsAgDUwZg8AQIBjzB4AAAQqKnsAgDXQjQ8AQIAzZDLZey2SRkc3PgAAAY7KHgBgDXTjAwAQ4JxOSSaelXf673P2dOMDABDgqOwBANZANz4AAAHOwsmebnwAAAIclT0AwBos/Lpckj0AwBIMwynDxMp1Zs71NZI9AMAaDMNcdc6YPQAAaKqo7AEA1mCYHLP348qeZA8AsAanU7KZGHf34zF7uvEBAAhwVPYAAGugGx8AgMBmOJ0yTHTj+/Ojd3TjAwAQ4KjsAQDWQDc+AAABzmlINmsme7rxAQAIcFT2AABrMAxJZp6z99/KnmQPALAEw2nIMNGNb5DsAQBo4gynzFX2PHoHAADOYsWKFerUqZPCw8OVmJio9957r9FjINkDACzBcBqmN0+9+OKLmjp1qubOnat9+/apV69eGjhwoI4fP94A3/DcSPYAAGswnOY3Dy1dulTjxo3TmDFj1KNHD2VmZqpFixZ67rnnGuALnptfj9mfmSxRY1T5OBKg4RiOSl+HADSYmh9+vhtj8luNqk29U6dG1ZKk0tJSt/awsDCFhYXVOr6qqko5OTmaNWuWqy0oKEjJycnKzs6ufyD14NfJ/uTJk5KkHSde9HEkQAMq8XUAQMM7efKkoqKiGuTaoaGhiouL0+7Cf5m+VqtWrRQfH+/WNnfuXM2bN6/Wsd9++60cDodiY2Pd2mNjY/XZZ5+ZjsUTfp3s7Xa7CgoKFBERIZvN5utwLKG0tFTx8fEqKChQZGSkr8MBvIqf78ZnGIZOnjwpu93eYPcIDw9Xfn6+qqrM9wIbhlEr35ytqm9q/DrZBwUFqX379r4Ow5IiIyP5ZYiAxc9342qoiv6nwsPDFR4e3uD3+anzzjtPwcHBKioqcmsvKipSXFxco8bCBD0AABpAaGio+vTpo23btrnanE6ntm3bpqSkpEaNxa8rewAAmrKpU6cqNTVVffv21eWXX65ly5apvLxcY8aMadQ4SPbwSFhYmObOnesXY1SAp/j5hrf96U9/0jfffKM5c+aosLBQvXv31pYtW2pN2mtoNsOfX/YLAAB+FWP2AAAEOJI9AAABjmQPAECAI9kDABDgSPaos6awTCPQEHbu3KmhQ4fKbrfLZrMpKyvL1yEBXkWyR500lWUagYZQXl6uXr16acWKFb4OBWgQPHqHOklMTNRll12mJ554QtLpt0DFx8dr0qRJmjlzpo+jA7zHZrNpw4YNGj58uK9DAbyGyh6/6swyjcnJya42Xy3TCADwHMkev+qXlmksLCz0UVQAgLoi2QMAEOBI9vhVTWmZRgCA50j2+FVNaZlGAIDnWPUOddJUlmkEGkJZWZkOHDjg+pyfn6/c3FzFxMSoQ4cOPowM8A4evUOdPfHEE3r44YddyzRmZGQoMTHR12EBpr399tsaMGBArfbU1FStWbOm8QMCvIxkDwBAgGPMHgCAAEeyBwAgwJHsAQAIcCR7AAACHMkeAIAAR7IHACDAkewBAAhwJHsAAAIcyR4w6Y477tDw4cNdn/v376/Jkyc3ehxvv/22bDabSkpKznmMzWZTVlZWna85b9489e7d21Rchw4dks1mU25urqnrAKg/kj0C0h133CGbzSabzabQ0FB17txZCxYsUE1NTYPf+9VXX9WDDz5Yp2PrkqABwCwWwkHAGjRokFavXq3Kykr961//0sSJE9WsWTPNmjWr1rFVVVUKDQ31yn1jYmK8ch0A8BYqewSssLAwxcXFqWPHjpowYYKSk5O1ceNGST92vS9atEh2u11du3aVJBUUFGjUqFGKjo5WTEyMhg0bpkOHDrmu6XA4NHXqVEVHR6tNmza677779PPlJX7ejV9ZWakZM2YoPj5eYWFh6ty5s5599lkdOnTItfhK69atZbPZdMcdd0g6vYRwenq6EhIS1Lx5c/Xq1Uv//Oc/3e7zr3/9SxdeeKGaN2+uAQMGuMVZVzNmzNCFF16oFi1a6IILLtDs2bNVXV1d67innnpK8fHxatGihUaNGqUTJ0647X/mmWfUvXt3hYeHq1u3bnryySc9jgVAwyHZwzKaN2+uqqoq1+dt27YpLy9PW7du1ebNm1VdXa2BAwcqIiJCu3bt0r///W+1atVKgwYNcp336KOPas2aNXruuee0e/duFRcXa8OGDb9439tvv13/+Mc/lJGRof379+upp55Sq1atFB8fr1deeUWSlJeXp6+//lqPP/64JCk9PV1r165VZmamPvnkE02ZMkW33nqrduzYIen0HyUjRozQ0KFDlZubqzvvvFMzZ870+N8kIiJCa9as0aeffqrHH39cq1at0mOPPeZ2zIEDB/TSSy9p06ZN2rJliz744APdddddrv3r1q3TnDlztGjRIu3fv1+LFy/W7Nmz9fzzz3scD4AGYgABKDU11Rg2bJhhGIbhdDqNrVu3GmFhYca0adNc+2NjY43KykrXOX//+9+Nrl27Gk6n09VWWVlpNG/e3HjjjTcMwzCMdu3aGUuWLHHtr66uNtq3b++6l2EYxjXXXGPcc889hmEYRl5eniHJ2Lp161njfOuttwxJxnfffedqq6ioMFq0aGG88847bseOHTvWuOWWWwzDMIxZs2YZPXr0cNs/Y8aMWtf6OUnGhg0bzrn/4YcfNvr06eP6PHfuXCM4ONj46quvXG2vv/66ERQUZHz99deGYRjGb3/7W2P9+vVu13nwwQeNpKQkwzAMIz8/35BkfPDBB+e8L4CGxZg9AtbmzZvVqlUrVVdXy+l06r//+781b9481/6ePXu6jdN/+OGHOnDggCIiItyuU1FRoYMHD+rEiRP6+uuvlZiY6NoXEhKivn371urKPyM3N1fBwcG65ppr6hz3gQMHdOrUKV133XVu7VVVVbrkkkskSfv373eLQ5KSkpLqfI8zXnzxRWVkZOjgwYMqKytTTU2NIiMj3Y7p0KGDzj//fLf7OJ1O5eXlKSIiQgcPHtTYsWM1btw41zE1NTWKioryOB4ADYNkj4A1YMAArVy5UqGhobLb7QoJcf9xb9mypdvnsrIy9enTR+vWrat1rd/85jf1iqF58+Yen1NWViZJeu2119ySrHR6HoK3ZGdnKyUlRfPnz9fAgQMVFRWlF154QY8++qjHsa5atarWHx/BwcFeixWAOSR7BKyWLVuqc+fOdT7+0ksv1Ysvvqi2bdvWqm7PaNeunfbs2aOrr75a0ukKNicnR5deeulZj+/Zs6ecTqd27Nih5OTkWvvP9Cw4HA5XW48ePRQWFqYjR46cs0ege/fursmGZ7z77ru//iV/4p133lHHjh11//33u9oOHz5c67gjR47o2LFjstvtrvsEBQWpa9euio2Nld1u15dffqmUlBSP7g+g8TBBD/hBSkqKzjvvPA0bNky7du1Sfn6+3n77bd1999366quvJEn33HOP/va3vykrK0ufffaZ7rrrrl98Rr5Tp05KTU3Vn//8Z2VlZbmu+dJLL0mSOnbsKJvNps2bN+ubb75RWVmZIiIiNG3aNE2ZMkXPP/+8Dh48qH379mn58uWuSW9//etf9cUXX2j69OnKy8vT+vXrtWbNGo++b5cuXXTkyBG98MILOnjwoDIyMs462TA8PFypqan68MMPtWvXLt19990aNWqU4uLiJEnz589Xenq6MjIy9Pnnn+ujjz7S6tWrtXTpUo/iAdBwSPbAD1q0aKGdO3eqQ4cOGjFihLp3766xY8eqoqLCVenfe++9uu2225SamqqkpCRFRETopptu+sXrrly5UjfffLPuuusudevWTePGjVN5ebkk6fzzz9f8+fM1c+ZMxcbGKi0tTZL04IMPavbs2UpPT1f37t01aNAgvfbaa0pISJB0ehz9lVdeUVZWlnr16qXMzEwtXrzYo+974403asqUKUpLS1Pv3r31zjvvaPbs2bWO69y5s0aMGKEhQ4bo+uuv18UXX+z2aN2dd96pZ555RqtXr1bPnj11zTXXaM2aNa5YAfiezTjXzCIAABAQqOwBAAhwJHsAAAIcyR4AgABHsgcAIMCR7AEACHAkewAAAhzJHgCAAEeyBwAgwJHsAQAIcCR7AAACHMkeAIAA9/8BoxKc4jMDJ0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model given validation data to make prediction\n",
    "predicted = model.predict(np.array(X_val))\n",
    "predicted = tf.squeeze(predicted)\n",
    "predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
    "actual = np.array(y_val)\n",
    "conf_mat = confusion_matrix(actual, predicted)\n",
    "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "displ.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 96.06741573033707%\n"
     ]
    }
   ],
   "source": [
    "# Validation percentage\n",
    "predictPerc = (conf_mat[0][0]+conf_mat[1][1])/(conf_mat[0][0]+conf_mat[0][1]+conf_mat[1][0]+conf_mat[1][1])*100\n",
    "print(f\"Prediction Accuracy: {predictPerc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the Trained Model\n",
    "# model_file = \"DeepVoiceModel.pkl\"\n",
    "\n",
    "# with open(model_file, \"wb\") as file:\n",
    "#     pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
