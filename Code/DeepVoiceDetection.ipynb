{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we will import all data here and launch all functionality\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.460546</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>2963.884687</td>\n",
       "      <td>3267.005972</td>\n",
       "      <td>5470.882196</td>\n",
       "      <td>0.072772</td>\n",
       "      <td>-367.00760</td>\n",
       "      <td>145.05531</td>\n",
       "      <td>-39.509342</td>\n",
       "      <td>9.740074</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.537854</td>\n",
       "      <td>-9.973751</td>\n",
       "      <td>-1.440740</td>\n",
       "      <td>-5.966642</td>\n",
       "      <td>-0.763765</td>\n",
       "      <td>-11.182472</td>\n",
       "      <td>-3.167860</td>\n",
       "      <td>-5.512184</td>\n",
       "      <td>-4.245675</td>\n",
       "      <td>-9.684337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.466253</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>2683.911773</td>\n",
       "      <td>3257.335666</td>\n",
       "      <td>5035.989139</td>\n",
       "      <td>0.059365</td>\n",
       "      <td>-397.97410</td>\n",
       "      <td>148.78825</td>\n",
       "      <td>-29.725275</td>\n",
       "      <td>12.238016</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.775922</td>\n",
       "      <td>-9.570081</td>\n",
       "      <td>-1.629141</td>\n",
       "      <td>-5.858627</td>\n",
       "      <td>-0.050287</td>\n",
       "      <td>-9.834495</td>\n",
       "      <td>-3.972230</td>\n",
       "      <td>-5.280860</td>\n",
       "      <td>-4.880746</td>\n",
       "      <td>-8.733951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.489474</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>3021.577717</td>\n",
       "      <td>3810.189311</td>\n",
       "      <td>6278.326559</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>-461.45007</td>\n",
       "      <td>137.25908</td>\n",
       "      <td>-10.904320</td>\n",
       "      <td>15.882215</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.320246</td>\n",
       "      <td>-9.588968</td>\n",
       "      <td>-2.252445</td>\n",
       "      <td>-5.581845</td>\n",
       "      <td>-0.747251</td>\n",
       "      <td>-7.970168</td>\n",
       "      <td>-3.635025</td>\n",
       "      <td>-5.040414</td>\n",
       "      <td>-4.510477</td>\n",
       "      <td>-7.133467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>3229.718116</td>\n",
       "      <td>3864.640276</td>\n",
       "      <td>6606.776386</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>-461.58685</td>\n",
       "      <td>133.97969</td>\n",
       "      <td>-14.545082</td>\n",
       "      <td>24.910967</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.770606</td>\n",
       "      <td>-10.215846</td>\n",
       "      <td>-3.263660</td>\n",
       "      <td>-7.869680</td>\n",
       "      <td>-1.856623</td>\n",
       "      <td>-10.158086</td>\n",
       "      <td>-3.120182</td>\n",
       "      <td>-5.020992</td>\n",
       "      <td>-2.269630</td>\n",
       "      <td>-7.375402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.455949</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>3086.336202</td>\n",
       "      <td>3451.406631</td>\n",
       "      <td>5734.066831</td>\n",
       "      <td>0.074854</td>\n",
       "      <td>-416.32126</td>\n",
       "      <td>133.45125</td>\n",
       "      <td>-15.054738</td>\n",
       "      <td>31.790266</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.761721</td>\n",
       "      <td>-12.843019</td>\n",
       "      <td>-3.643779</td>\n",
       "      <td>-6.995357</td>\n",
       "      <td>-3.861711</td>\n",
       "      <td>-10.737380</td>\n",
       "      <td>-3.649080</td>\n",
       "      <td>-4.974201</td>\n",
       "      <td>-1.522852</td>\n",
       "      <td>-8.856704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>0.412818</td>\n",
       "      <td>0.066892</td>\n",
       "      <td>2583.068619</td>\n",
       "      <td>2829.326169</td>\n",
       "      <td>5163.795975</td>\n",
       "      <td>0.060236</td>\n",
       "      <td>-333.78262</td>\n",
       "      <td>144.71512</td>\n",
       "      <td>-20.789537</td>\n",
       "      <td>11.582300</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.846725</td>\n",
       "      <td>-1.896972</td>\n",
       "      <td>-3.274629</td>\n",
       "      <td>-3.990192</td>\n",
       "      <td>-1.307747</td>\n",
       "      <td>-0.528529</td>\n",
       "      <td>-1.292468</td>\n",
       "      <td>-3.600915</td>\n",
       "      <td>0.689428</td>\n",
       "      <td>-2.756658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>0.395530</td>\n",
       "      <td>0.073642</td>\n",
       "      <td>2424.784135</td>\n",
       "      <td>2810.715089</td>\n",
       "      <td>4816.930970</td>\n",
       "      <td>0.053438</td>\n",
       "      <td>-331.97443</td>\n",
       "      <td>149.60684</td>\n",
       "      <td>-23.136524</td>\n",
       "      <td>7.226769</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.704117</td>\n",
       "      <td>-0.982102</td>\n",
       "      <td>-3.566548</td>\n",
       "      <td>-3.882155</td>\n",
       "      <td>-1.297153</td>\n",
       "      <td>-0.719066</td>\n",
       "      <td>-2.619748</td>\n",
       "      <td>-3.978990</td>\n",
       "      <td>0.434549</td>\n",
       "      <td>-2.585578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>0.393038</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>2226.744955</td>\n",
       "      <td>2723.591431</td>\n",
       "      <td>4161.055770</td>\n",
       "      <td>0.048795</td>\n",
       "      <td>-334.36398</td>\n",
       "      <td>156.39316</td>\n",
       "      <td>-23.255356</td>\n",
       "      <td>-3.817101</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.001995</td>\n",
       "      <td>0.186833</td>\n",
       "      <td>-2.866827</td>\n",
       "      <td>-2.730880</td>\n",
       "      <td>-0.201203</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>-3.587965</td>\n",
       "      <td>-4.461579</td>\n",
       "      <td>-0.619438</td>\n",
       "      <td>-2.696462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>0.407273</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>2268.316346</td>\n",
       "      <td>2813.686815</td>\n",
       "      <td>4415.420109</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>-345.40338</td>\n",
       "      <td>153.21498</td>\n",
       "      <td>-16.308151</td>\n",
       "      <td>-1.320045</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.911846</td>\n",
       "      <td>0.151382</td>\n",
       "      <td>-3.383205</td>\n",
       "      <td>-3.434818</td>\n",
       "      <td>0.375495</td>\n",
       "      <td>0.492073</td>\n",
       "      <td>-2.429903</td>\n",
       "      <td>-3.093830</td>\n",
       "      <td>-0.295001</td>\n",
       "      <td>-3.339307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>0.419693</td>\n",
       "      <td>0.068031</td>\n",
       "      <td>2447.142638</td>\n",
       "      <td>2970.737301</td>\n",
       "      <td>5169.617870</td>\n",
       "      <td>0.051633</td>\n",
       "      <td>-350.34167</td>\n",
       "      <td>150.72937</td>\n",
       "      <td>-10.403403</td>\n",
       "      <td>4.240970</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.831195</td>\n",
       "      <td>-0.608796</td>\n",
       "      <td>-2.863230</td>\n",
       "      <td>-3.722685</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>0.177249</td>\n",
       "      <td>-1.701163</td>\n",
       "      <td>-1.813252</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>-3.648574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5912 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n",
       "0        0.460546  0.019600        2963.884687         3267.005972   \n",
       "1        0.466253  0.014279        2683.911773         3257.335666   \n",
       "2        0.489474  0.009028        3021.577717         3810.189311   \n",
       "3        0.486911  0.009545        3229.718116         3864.640276   \n",
       "4        0.455949  0.014331        3086.336202         3451.406631   \n",
       "...           ...       ...                ...                 ...   \n",
       "5907     0.412818  0.066892        2583.068619         2829.326169   \n",
       "5908     0.395530  0.073642        2424.784135         2810.715089   \n",
       "5909     0.393038  0.068612        2226.744955         2723.591431   \n",
       "5910     0.407273  0.064328        2268.316346         2813.686815   \n",
       "5911     0.419693  0.068031        2447.142638         2970.737301   \n",
       "\n",
       "          rolloff  zero_crossing_rate      mfcc1      mfcc2      mfcc3  \\\n",
       "0     5470.882196            0.072772 -367.00760  145.05531 -39.509342   \n",
       "1     5035.989139            0.059365 -397.97410  148.78825 -29.725275   \n",
       "2     6278.326559            0.060115 -461.45007  137.25908 -10.904320   \n",
       "3     6606.776386            0.069307 -461.58685  133.97969 -14.545082   \n",
       "4     5734.066831            0.074854 -416.32126  133.45125 -15.054738   \n",
       "...           ...                 ...        ...        ...        ...   \n",
       "5907  5163.795975            0.060236 -333.78262  144.71512 -20.789537   \n",
       "5908  4816.930970            0.053438 -331.97443  149.60684 -23.136524   \n",
       "5909  4161.055770            0.048795 -334.36398  156.39316 -23.255356   \n",
       "5910  4415.420109            0.048171 -345.40338  153.21498 -16.308151   \n",
       "5911  5169.617870            0.051633 -350.34167  150.72937 -10.403403   \n",
       "\n",
       "          mfcc4  ...    mfcc11     mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0      9.740074  ... -6.537854  -9.973751 -1.440740 -5.966642 -0.763765   \n",
       "1     12.238016  ... -7.775922  -9.570081 -1.629141 -5.858627 -0.050287   \n",
       "2     15.882215  ... -8.320246  -9.588968 -2.252445 -5.581845 -0.747251   \n",
       "3     24.910967  ... -7.770606 -10.215846 -3.263660 -7.869680 -1.856623   \n",
       "4     31.790266  ... -9.761721 -12.843019 -3.643779 -6.995357 -3.861711   \n",
       "...         ...  ...       ...        ...       ...       ...       ...   \n",
       "5907  11.582300  ... -8.846725  -1.896972 -3.274629 -3.990192 -1.307747   \n",
       "5908   7.226769  ... -7.704117  -0.982102 -3.566548 -3.882155 -1.297153   \n",
       "5909  -3.817101  ... -7.001995   0.186833 -2.866827 -2.730880 -0.201203   \n",
       "5910  -1.320045  ... -7.911846   0.151382 -3.383205 -3.434818  0.375495   \n",
       "5911   4.240970  ... -8.831195  -0.608796 -2.863230 -3.722685  0.101040   \n",
       "\n",
       "         mfcc16    mfcc17    mfcc18    mfcc19    mfcc20  \n",
       "0    -11.182472 -3.167860 -5.512184 -4.245675 -9.684337  \n",
       "1     -9.834495 -3.972230 -5.280860 -4.880746 -8.733951  \n",
       "2     -7.970168 -3.635025 -5.040414 -4.510477 -7.133467  \n",
       "3    -10.158086 -3.120182 -5.020992 -2.269630 -7.375402  \n",
       "4    -10.737380 -3.649080 -4.974201 -1.522852 -8.856704  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "5907  -0.528529 -1.292468 -3.600915  0.689428 -2.756658  \n",
       "5908  -0.719066 -2.619748 -3.978990  0.434549 -2.585578  \n",
       "5909  -0.480000 -3.587965 -4.461579 -0.619438 -2.696462  \n",
       "5910   0.492073 -2.429903 -3.093830 -0.295001 -3.339307  \n",
       "5911   0.177249 -1.701163 -1.813252  0.173714 -3.648574  \n",
       "\n",
       "[5912 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert balanced csv into dataframe and seperate labels\n",
    "DATASET_PATH = \"/Users/connormaclachlan/Desktop/CS433_Project/Code/audio_features2.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "data = df.iloc[:,:-1]\n",
    "labels = df.iloc[:,-1]\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "labels = labels.ravel()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into tensorflow dataset\n",
    "def convertToDataset(data, labels):\n",
    "    return tf.data.Dataset.zip(tf.data.Dataset.from_tensor_slices(data), tf.data.Dataset.from_tensor_slices(labels))\n",
    "\n",
    "# Process dataset\n",
    "def processData(data, labels):\n",
    "    data = tf.abs(data)\n",
    "    data = tf.expand_dims(data, axis=1)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.10, random_state=42)\n",
    "\n",
    "trainDataset = convertToDataset(X_train, y_train)\n",
    "testDataset = convertToDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.34771500e-01,  2.88258340e-02,  2.95657240e+03,  3.12244336e+03,\n",
       "         5.69613706e+03,  7.52296692e-02, -3.32747860e+02,  1.42060130e+02,\n",
       "        -5.10173840e+01,  2.65516720e+01, -2.30403400e+01,  1.31221510e+01,\n",
       "        -4.83686160e+00, -1.63952080e+01, -5.59854100e+00, -1.61675110e+01,\n",
       "        -1.58248260e+00, -1.81260410e+01, -1.98251720e+00, -2.50885060e+00,\n",
       "        -8.38363600e+00, -1.18850960e+00, -7.47049760e+00,  3.05572150e-01,\n",
       "        -5.17679900e+00, -4.52124500e+00]),\n",
       " 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4138, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "trainDataset = trainDataset.map(processData)\n",
    "trainDataset = trainDataset.cache()\n",
    "trainDataset = trainDataset.batch(64)\n",
    "trainDataset = trainDataset.prefetch(32)\n",
    "\n",
    "testDataset = testDataset.map(processData)\n",
    "testDataset = testDataset.cache()\n",
    "testDataset = testDataset.batch(64)\n",
    "testDataset = testDataset.prefetch(32)\n",
    "\n",
    "X_val = abs(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 16.2093 - accuracy: 0.7199\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7680 - accuracy: 0.8185\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8726\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8842\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8898\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8978\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.3244 - accuracy: 0.9036\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.3236 - accuracy: 0.9058\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.9024\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.9050\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.9084\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.9101\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9067\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.9087\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.9128\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.9120\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.9178\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9241\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9178\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.9128\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9292\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9316\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9338\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9335\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9364\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9355\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9413\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9422\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9432\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9447\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9456\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9425\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9432\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9432\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9449\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9461\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9413\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9459\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9471\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9447\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9502\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9531\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9454\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9497\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9497\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9485\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9493\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9505\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9526\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9529\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9497\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9534\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9577\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9531\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9572\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9565\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9570\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9575\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9575\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9570\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9594\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9575\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9611\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9567\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9553\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9609\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9538\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9592\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9587\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1351 - accuracy: 0.9594\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9640\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9601\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9628\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9601\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9601\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9642\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9558\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9642\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9623\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9618\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9618\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9657\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9662\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9647\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9623\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9555\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9618\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9616\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9575\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9645\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9654\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9657\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1395 - accuracy: 0.9561\n",
      "Test Accuracy: 0.9561403393745422\n",
      "Test Loss: 0.13952267169952393\n"
     ]
    }
   ],
   "source": [
    "# Define the NN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(26,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainDataset, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(testDataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8180364dc0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model given validation data to make prediction\n",
    "predicted = model.predict(np.array(X_val))\n",
    "predicted = tf.squeeze(predicted)\n",
    "predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
    "actual = np.array(y_val)\n",
    "conf_mat = confusion_matrix(actual, predicted)\n",
    "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "displ.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 95.50561797752809%\n"
     ]
    }
   ],
   "source": [
    "# Validation percentage\n",
    "predictPerc = (conf_mat[0][0]+conf_mat[1][1])/(conf_mat[0][0]+conf_mat[0][1]+conf_mat[1][0]+conf_mat[1][1])*100\n",
    "print(f\"Prediction Accuracy: {predictPerc}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
