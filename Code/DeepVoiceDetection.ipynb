{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
=======
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [],
   "source": [
    "\"\"\"we will import all data here and launch all functionality\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
=======
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338055</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>2842.948867</td>\n",
       "      <td>4322.916759</td>\n",
       "      <td>6570.586186</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>-462.169586</td>\n",
       "      <td>90.311272</td>\n",
       "      <td>19.073769</td>\n",
       "      <td>24.046888</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.181895</td>\n",
       "      <td>-6.686564</td>\n",
       "      <td>0.902086</td>\n",
       "      <td>-7.251551</td>\n",
       "      <td>-1.198342</td>\n",
       "      <td>4.747403</td>\n",
       "      <td>-4.986279</td>\n",
       "      <td>0.953935</td>\n",
       "      <td>-5.013138</td>\n",
       "      <td>-6.779060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443766</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>2336.129597</td>\n",
       "      <td>3445.777044</td>\n",
       "      <td>3764.949874</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>-409.413422</td>\n",
       "      <td>120.348808</td>\n",
       "      <td>-7.161531</td>\n",
       "      <td>5.114784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372541</td>\n",
       "      <td>-2.131157</td>\n",
       "      <td>-6.876417</td>\n",
       "      <td>-1.359395</td>\n",
       "      <td>0.326401</td>\n",
       "      <td>-5.420016</td>\n",
       "      <td>-2.109968</td>\n",
       "      <td>-1.757634</td>\n",
       "      <td>-9.537907</td>\n",
       "      <td>-8.494421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302528</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>2692.988386</td>\n",
       "      <td>2861.133180</td>\n",
       "      <td>4716.610271</td>\n",
       "      <td>0.080342</td>\n",
       "      <td>-318.996033</td>\n",
       "      <td>120.490273</td>\n",
       "      <td>-24.625771</td>\n",
       "      <td>23.891073</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.099179</td>\n",
       "      <td>-5.853725</td>\n",
       "      <td>-3.724773</td>\n",
       "      <td>-6.627182</td>\n",
       "      <td>-5.117002</td>\n",
       "      <td>-6.072106</td>\n",
       "      <td>-0.994653</td>\n",
       "      <td>-1.617120</td>\n",
       "      <td>-3.922354</td>\n",
       "      <td>-7.033001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319933</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>2241.665382</td>\n",
       "      <td>3503.766175</td>\n",
       "      <td>3798.641521</td>\n",
       "      <td>0.047180</td>\n",
       "      <td>-404.636749</td>\n",
       "      <td>136.320908</td>\n",
       "      <td>2.308172</td>\n",
       "      <td>-3.907071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513633</td>\n",
       "      <td>-1.898315</td>\n",
       "      <td>-2.046493</td>\n",
       "      <td>-7.176277</td>\n",
       "      <td>-3.293508</td>\n",
       "      <td>4.209121</td>\n",
       "      <td>0.121835</td>\n",
       "      <td>-5.407063</td>\n",
       "      <td>-3.654926</td>\n",
       "      <td>-3.274857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420055</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>2526.069123</td>\n",
       "      <td>3102.659519</td>\n",
       "      <td>5025.077899</td>\n",
       "      <td>0.051905</td>\n",
       "      <td>-410.497925</td>\n",
       "      <td>152.731400</td>\n",
       "      <td>-18.266771</td>\n",
       "      <td>51.993462</td>\n",
       "      <td>...</td>\n",
       "      <td>11.086248</td>\n",
       "      <td>-1.952340</td>\n",
       "      <td>0.810868</td>\n",
       "      <td>6.238493</td>\n",
       "      <td>6.555839</td>\n",
       "      <td>7.535542</td>\n",
       "      <td>2.849219</td>\n",
       "      <td>2.616843</td>\n",
       "      <td>-1.793357</td>\n",
       "      <td>-5.060998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11773</th>\n",
       "      <td>0.435426</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>2772.575031</td>\n",
       "      <td>2728.757601</td>\n",
       "      <td>4998.670213</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>-342.309753</td>\n",
       "      <td>144.490418</td>\n",
       "      <td>-79.272942</td>\n",
       "      <td>8.890874</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.950688</td>\n",
       "      <td>-17.982819</td>\n",
       "      <td>-7.831161</td>\n",
       "      <td>-1.127167</td>\n",
       "      <td>-7.669674</td>\n",
       "      <td>-0.653850</td>\n",
       "      <td>-8.037575</td>\n",
       "      <td>-2.671002</td>\n",
       "      <td>-4.483765</td>\n",
       "      <td>-3.355975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11774</th>\n",
       "      <td>0.454611</td>\n",
       "      <td>0.070578</td>\n",
       "      <td>1029.274601</td>\n",
       "      <td>1519.231563</td>\n",
       "      <td>1922.927486</td>\n",
       "      <td>0.026553</td>\n",
       "      <td>-332.230408</td>\n",
       "      <td>202.603012</td>\n",
       "      <td>-0.181929</td>\n",
       "      <td>-2.146542</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.910435</td>\n",
       "      <td>-2.018668</td>\n",
       "      <td>-2.705635</td>\n",
       "      <td>-1.589172</td>\n",
       "      <td>-2.938737</td>\n",
       "      <td>-0.972690</td>\n",
       "      <td>-1.706672</td>\n",
       "      <td>-2.796168</td>\n",
       "      <td>2.171270</td>\n",
       "      <td>-1.660128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11775</th>\n",
       "      <td>0.374432</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>4063.645317</td>\n",
       "      <td>3558.261357</td>\n",
       "      <td>7299.133512</td>\n",
       "      <td>0.110278</td>\n",
       "      <td>-372.149109</td>\n",
       "      <td>92.670235</td>\n",
       "      <td>-29.082432</td>\n",
       "      <td>59.736637</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.552000</td>\n",
       "      <td>-6.628118</td>\n",
       "      <td>-3.827499</td>\n",
       "      <td>-7.287946</td>\n",
       "      <td>-2.899543</td>\n",
       "      <td>-11.508186</td>\n",
       "      <td>-1.296590</td>\n",
       "      <td>-14.325416</td>\n",
       "      <td>-4.405540</td>\n",
       "      <td>-15.869982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11776</th>\n",
       "      <td>0.410885</td>\n",
       "      <td>0.090499</td>\n",
       "      <td>1124.655596</td>\n",
       "      <td>1553.651133</td>\n",
       "      <td>2065.942806</td>\n",
       "      <td>0.031761</td>\n",
       "      <td>-328.062805</td>\n",
       "      <td>193.557526</td>\n",
       "      <td>6.779151</td>\n",
       "      <td>-1.304731</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.348275</td>\n",
       "      <td>-5.437202</td>\n",
       "      <td>-4.252508</td>\n",
       "      <td>-1.258683</td>\n",
       "      <td>-2.107233</td>\n",
       "      <td>-1.018154</td>\n",
       "      <td>-2.716950</td>\n",
       "      <td>-3.681598</td>\n",
       "      <td>3.811063</td>\n",
       "      <td>3.948419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11777</th>\n",
       "      <td>0.570581</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>2275.915286</td>\n",
       "      <td>3566.472303</td>\n",
       "      <td>4054.590126</td>\n",
       "      <td>0.052983</td>\n",
       "      <td>-398.812103</td>\n",
       "      <td>129.081482</td>\n",
       "      <td>3.654665</td>\n",
       "      <td>18.412062</td>\n",
       "      <td>...</td>\n",
       "      <td>4.769826</td>\n",
       "      <td>4.484940</td>\n",
       "      <td>3.916474</td>\n",
       "      <td>2.186594</td>\n",
       "      <td>1.218625</td>\n",
       "      <td>3.607651</td>\n",
       "      <td>4.629877</td>\n",
       "      <td>0.414103</td>\n",
       "      <td>5.229393</td>\n",
       "      <td>0.214607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11778 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n",
       "0         0.338055  0.027948        2842.948867         4322.916759   \n",
       "1         0.443766  0.037838        2336.129597         3445.777044   \n",
       "2         0.302528  0.056578        2692.988386         2861.133180   \n",
       "3         0.319933  0.031504        2241.665382         3503.766175   \n",
       "4         0.420055  0.016158        2526.069123         3102.659519   \n",
       "...            ...       ...                ...                 ...   \n",
       "11773     0.435426  0.025303        2772.575031         2728.757601   \n",
       "11774     0.454611  0.070578        1029.274601         1519.231563   \n",
       "11775     0.374432  0.019063        4063.645317         3558.261357   \n",
       "11776     0.410885  0.090499        1124.655596         1553.651133   \n",
       "11777     0.570581  0.033022        2275.915286         3566.472303   \n",
       "\n",
       "           rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n",
       "0      6570.586186            0.041050 -462.169586   90.311272  19.073769   \n",
       "1      3764.949874            0.047730 -409.413422  120.348808  -7.161531   \n",
       "2      4716.610271            0.080342 -318.996033  120.490273 -24.625771   \n",
       "3      3798.641521            0.047180 -404.636749  136.320908   2.308172   \n",
       "4      5025.077899            0.051905 -410.497925  152.731400 -18.266771   \n",
       "...            ...                 ...         ...         ...        ...   \n",
       "11773  4998.670213            0.074323 -342.309753  144.490418 -79.272942   \n",
       "11774  1922.927486            0.026553 -332.230408  202.603012  -0.181929   \n",
       "11775  7299.133512            0.110278 -372.149109   92.670235 -29.082432   \n",
       "11776  2065.942806            0.031761 -328.062805  193.557526   6.779151   \n",
       "11777  4054.590126            0.052983 -398.812103  129.081482   3.654665   \n",
       "\n",
       "           mfcc4  ...     mfcc11     mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0      24.046888  ... -14.181895  -6.686564  0.902086 -7.251551 -1.198342   \n",
       "1       5.114784  ...   0.372541  -2.131157 -6.876417 -1.359395  0.326401   \n",
       "2      23.891073  ...  -3.099179  -5.853725 -3.724773 -6.627182 -5.117002   \n",
       "3      -3.907071  ...   1.513633  -1.898315 -2.046493 -7.176277 -3.293508   \n",
       "4      51.993462  ...  11.086248  -1.952340  0.810868  6.238493  6.555839   \n",
       "...          ...  ...        ...        ...       ...       ...       ...   \n",
       "11773   8.890874  ...  -2.950688 -17.982819 -7.831161 -1.127167 -7.669674   \n",
       "11774  -2.146542  ...  -2.910435  -2.018668 -2.705635 -1.589172 -2.938737   \n",
       "11775  59.736637  ... -17.552000  -6.628118 -3.827499 -7.287946 -2.899543   \n",
       "11776  -1.304731  ...  -7.348275  -5.437202 -4.252508 -1.258683 -2.107233   \n",
       "11777  18.412062  ...   4.769826   4.484940  3.916474  2.186594  1.218625   \n",
       "\n",
       "          mfcc16    mfcc17     mfcc18    mfcc19     mfcc20  \n",
       "0       4.747403 -4.986279   0.953935 -5.013138  -6.779060  \n",
       "1      -5.420016 -2.109968  -1.757634 -9.537907  -8.494421  \n",
       "2      -6.072106 -0.994653  -1.617120 -3.922354  -7.033001  \n",
       "3       4.209121  0.121835  -5.407063 -3.654926  -3.274857  \n",
       "4       7.535542  2.849219   2.616843 -1.793357  -5.060998  \n",
       "...          ...       ...        ...       ...        ...  \n",
       "11773  -0.653850 -8.037575  -2.671002 -4.483765  -3.355975  \n",
       "11774  -0.972690 -1.706672  -2.796168  2.171270  -1.660128  \n",
       "11775 -11.508186 -1.296590 -14.325416 -4.405540 -15.869982  \n",
       "11776  -1.018154 -2.716950  -3.681598  3.811063   3.948419  \n",
       "11777   3.607651  4.629877   0.414103  5.229393   0.214607  \n",
       "\n",
       "[11778 rows x 26 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 32,
=======
     "execution_count": 2,
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert balanced csv into dataframe and seperate labels\n",
    "DATASET_PATH = \"/Users/ethanhyde/Documents/CS433_Project/KAGGLE/DATASET-balanced.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "data = df.iloc[:,:-1]\n",
    "labels = df.iloc[:,-1]\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "labels = labels.ravel()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
=======
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [],
   "source": [
    "# Convert data into tensorflow dataset\n",
    "def convertToDataset(data, labels):\n",
    "    return tf.data.Dataset.zip(tf.data.Dataset.from_tensor_slices(data), tf.data.Dataset.from_tensor_slices(labels))\n",
    "\n",
    "# Process dataset\n",
    "def processData(data, labels):\n",
    "    data = tf.abs(data)\n",
    "    data = tf.expand_dims(data, axis=1)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
=======
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [],
   "source": [
    "# Split data into training and testing and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.10, random_state=42)\n",
    "\n",
    "trainDataset = convertToDataset(X_train, y_train)\n",
    "testDataset = convertToDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
=======
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.98713000e-01,  4.40390000e-02,  3.25821094e+03,  3.85114700e+03,\n",
       "         6.83959255e+03,  8.13260000e-02, -3.67204224e+02,  1.34100235e+02,\n",
       "         4.87364100e+00,  2.30041580e+01,  1.04666810e+01,  5.70958000e-01,\n",
       "        -2.51008210e+01,  5.90441100e+00, -4.06430200e+00,  2.09046700e+00,\n",
       "        -6.00957800e+00,  6.85579500e+00, -7.11480500e+00, -1.39212100e+00,\n",
       "        -5.72690200e+00,  3.22187300e+00, -3.89038000e-01, -3.91204000e-01,\n",
       "        -1.62757600e+00,  4.55036000e-01]),\n",
       " 0)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 35,
=======
     "execution_count": 5,
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
=======
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "outputs": [],
   "source": [
    "# Data processing\n",
    "trainDataset = trainDataset.map(processData)\n",
    "trainDataset = trainDataset.cache()\n",
    "trainDataset = trainDataset.batch(64)\n",
    "trainDataset = trainDataset.prefetch(32)\n",
    "\n",
    "testDataset = testDataset.map(processData)\n",
    "testDataset = testDataset.cache()\n",
    "testDataset = testDataset.batch(64)\n",
    "testDataset = testDataset.prefetch(32)\n",
    "\n",
    "X_val = abs(X_val)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
   "source": [
    "# Hyperparameters\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "129/129 [==============================] - 2s 4ms/step - loss: 4.1208 - accuracy: 0.6386\n",
      "Epoch 2/100\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.7664 - accuracy: 0.6959\n",
      "Epoch 3/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5932 - accuracy: 0.7008\n",
      "Epoch 4/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5377 - accuracy: 0.7117\n",
      "Epoch 5/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.7433\n",
      "Epoch 6/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2601 - accuracy: 0.7334\n",
      "Epoch 7/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.9236 - accuracy: 0.7671\n",
      "Epoch 8/100\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.7847\n",
      "Epoch 9/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.7823\n",
      "Epoch 10/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.9789 - accuracy: 0.7576\n",
      "Epoch 11/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.8096\n",
      "Epoch 12/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8096\n",
      "Epoch 13/100\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.8070\n",
      "Epoch 14/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.8009\n",
      "Epoch 15/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8262\n",
      "Epoch 17/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.7945\n",
      "Epoch 18/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.8049\n",
      "Epoch 19/100\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5360 - accuracy: 0.8176\n",
      "Epoch 20/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8296\n",
      "Epoch 21/100\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.8224\n",
      "Epoch 22/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8358\n",
      "Epoch 23/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8395\n",
      "Epoch 24/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8484\n",
      "Epoch 25/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8385\n",
      "Epoch 26/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8444\n",
      "Epoch 27/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8476\n",
      "Epoch 28/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8501\n",
      "Epoch 29/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8504\n",
      "Epoch 31/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8467\n",
      "Epoch 32/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8547\n",
      "Epoch 33/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8632\n",
      "Epoch 36/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8598\n",
      "Epoch 37/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8612\n",
      "Epoch 38/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8668\n",
      "Epoch 39/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8684\n",
      "Epoch 40/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8679\n",
      "Epoch 41/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8730\n",
      "Epoch 42/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8702\n",
      "Epoch 43/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8713\n",
      "Epoch 44/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8789\n",
      "Epoch 45/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8774\n",
      "Epoch 46/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8768\n",
      "Epoch 47/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8812\n",
      "Epoch 48/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8793\n",
      "Epoch 49/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8819\n",
      "Epoch 50/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8842\n",
      "Epoch 51/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8850\n",
      "Epoch 52/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8865\n",
      "Epoch 53/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8857\n",
      "Epoch 54/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8811\n",
      "Epoch 55/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8810\n",
      "Epoch 56/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8799\n",
      "Epoch 57/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8772\n",
      "Epoch 58/100\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8740\n",
      "Epoch 59/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8679\n",
      "Epoch 60/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8779\n",
      "Epoch 61/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8806\n",
      "Epoch 62/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8840\n",
      "Epoch 63/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8882\n",
      "Epoch 64/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8901\n",
      "Epoch 65/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.8925\n",
      "Epoch 66/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8923\n",
      "Epoch 67/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8964\n",
      "Epoch 68/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.8965\n",
      "Epoch 69/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.8956\n",
      "Epoch 70/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8896\n",
      "Epoch 71/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8937\n",
      "Epoch 72/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.8951\n",
      "Epoch 73/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.8993\n",
      "Epoch 74/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.8951\n",
      "Epoch 75/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9024\n",
      "Epoch 76/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9020\n",
      "Epoch 77/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9033\n",
      "Epoch 78/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9009\n",
      "Epoch 79/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9061\n",
      "Epoch 80/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2344 - accuracy: 0.9004\n",
      "Epoch 81/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9044\n",
      "Epoch 82/100\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.2275 - accuracy: 0.9053\n",
      "Epoch 83/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9072\n",
      "Epoch 84/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9095\n",
      "Epoch 85/100\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9112\n",
      "Epoch 86/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9032\n",
      "Epoch 87/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9084\n",
      "Epoch 88/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9135\n",
      "Epoch 89/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9138\n",
      "Epoch 90/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9148\n",
      "Epoch 91/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9190\n",
      "Epoch 92/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9125\n",
      "Epoch 93/100\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9212\n",
      "Epoch 94/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9197\n",
      "Epoch 95/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9241\n",
      "Epoch 96/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9231\n",
      "Epoch 97/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9260\n",
      "Epoch 98/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9205\n",
      "Epoch 99/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9224\n",
      "Epoch 100/100\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9262\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9368\n",
      "Test Accuracy: 0.9367924332618713\n",
      "Test Loss: 0.18409296870231628\n"
=======
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the NN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      3\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m26\u001b[39m,)),\n\u001b[1;32m      4\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinaryCrossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
     ]
    }
   ],
   "source": [
    "# Define the NN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(26,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainDataset, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(testDataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb18ca799a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model given validation data to make prediction\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(X_val))\n\u001b[1;32m      3\u001b[0m predicted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(predicted)\n\u001b[1;32m      4\u001b[0m predicted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m predicted])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
    }
   ],
   "source": [
    "# Model given validation data to make prediction\n",
    "predicted = model.predict(np.array(X_val))\n",
    "predicted = tf.squeeze(predicted)\n",
    "predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
    "actual = np.array(y_val)\n",
    "conf_mat = confusion_matrix(actual, predicted)\n",
    "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "displ.plot()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 92.65536723163842%\n"
=======
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conf_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Validation percentage\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictPerc \u001b[38;5;241m=\u001b[39m (conf_mat[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mconf_mat[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m(conf_mat[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mconf_mat[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mconf_mat[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mconf_mat[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictPerc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conf_mat' is not defined"
>>>>>>> da841b3118cf38c7ea013e50a62040f3ef13a864
     ]
    }
   ],
   "source": [
    "# Validation accuracy percentage\n",
    "predictPerc = (conf_mat[0][0]+conf_mat[1][1])/(conf_mat[0][0]+conf_mat[0][1]+conf_mat[1][0]+conf_mat[1][1])*100\n",
    "print(f\"Prediction Accuracy: {predictPerc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "\u001b[1;31m[notice] To update, run: python3.12 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
