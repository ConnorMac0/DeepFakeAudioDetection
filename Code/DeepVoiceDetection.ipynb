{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338055</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>2842.948867</td>\n",
       "      <td>4322.916759</td>\n",
       "      <td>6570.586186</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>-462.169586</td>\n",
       "      <td>90.311272</td>\n",
       "      <td>19.073769</td>\n",
       "      <td>24.046888</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.181895</td>\n",
       "      <td>-6.686564</td>\n",
       "      <td>0.902086</td>\n",
       "      <td>-7.251551</td>\n",
       "      <td>-1.198342</td>\n",
       "      <td>4.747403</td>\n",
       "      <td>-4.986279</td>\n",
       "      <td>0.953935</td>\n",
       "      <td>-5.013138</td>\n",
       "      <td>-6.779060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443766</td>\n",
       "      <td>0.037838</td>\n",
       "      <td>2336.129597</td>\n",
       "      <td>3445.777044</td>\n",
       "      <td>3764.949874</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>-409.413422</td>\n",
       "      <td>120.348808</td>\n",
       "      <td>-7.161531</td>\n",
       "      <td>5.114784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372541</td>\n",
       "      <td>-2.131157</td>\n",
       "      <td>-6.876417</td>\n",
       "      <td>-1.359395</td>\n",
       "      <td>0.326401</td>\n",
       "      <td>-5.420016</td>\n",
       "      <td>-2.109968</td>\n",
       "      <td>-1.757634</td>\n",
       "      <td>-9.537907</td>\n",
       "      <td>-8.494421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302528</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>2692.988386</td>\n",
       "      <td>2861.133180</td>\n",
       "      <td>4716.610271</td>\n",
       "      <td>0.080342</td>\n",
       "      <td>-318.996033</td>\n",
       "      <td>120.490273</td>\n",
       "      <td>-24.625771</td>\n",
       "      <td>23.891073</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.099179</td>\n",
       "      <td>-5.853725</td>\n",
       "      <td>-3.724773</td>\n",
       "      <td>-6.627182</td>\n",
       "      <td>-5.117002</td>\n",
       "      <td>-6.072106</td>\n",
       "      <td>-0.994653</td>\n",
       "      <td>-1.617120</td>\n",
       "      <td>-3.922354</td>\n",
       "      <td>-7.033001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319933</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>2241.665382</td>\n",
       "      <td>3503.766175</td>\n",
       "      <td>3798.641521</td>\n",
       "      <td>0.047180</td>\n",
       "      <td>-404.636749</td>\n",
       "      <td>136.320908</td>\n",
       "      <td>2.308172</td>\n",
       "      <td>-3.907071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513633</td>\n",
       "      <td>-1.898315</td>\n",
       "      <td>-2.046493</td>\n",
       "      <td>-7.176277</td>\n",
       "      <td>-3.293508</td>\n",
       "      <td>4.209121</td>\n",
       "      <td>0.121835</td>\n",
       "      <td>-5.407063</td>\n",
       "      <td>-3.654926</td>\n",
       "      <td>-3.274857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420055</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>2526.069123</td>\n",
       "      <td>3102.659519</td>\n",
       "      <td>5025.077899</td>\n",
       "      <td>0.051905</td>\n",
       "      <td>-410.497925</td>\n",
       "      <td>152.731400</td>\n",
       "      <td>-18.266771</td>\n",
       "      <td>51.993462</td>\n",
       "      <td>...</td>\n",
       "      <td>11.086248</td>\n",
       "      <td>-1.952340</td>\n",
       "      <td>0.810868</td>\n",
       "      <td>6.238493</td>\n",
       "      <td>6.555839</td>\n",
       "      <td>7.535542</td>\n",
       "      <td>2.849219</td>\n",
       "      <td>2.616843</td>\n",
       "      <td>-1.793357</td>\n",
       "      <td>-5.060998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11773</th>\n",
       "      <td>0.435426</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>2772.575031</td>\n",
       "      <td>2728.757601</td>\n",
       "      <td>4998.670213</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>-342.309753</td>\n",
       "      <td>144.490418</td>\n",
       "      <td>-79.272942</td>\n",
       "      <td>8.890874</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.950688</td>\n",
       "      <td>-17.982819</td>\n",
       "      <td>-7.831161</td>\n",
       "      <td>-1.127167</td>\n",
       "      <td>-7.669674</td>\n",
       "      <td>-0.653850</td>\n",
       "      <td>-8.037575</td>\n",
       "      <td>-2.671002</td>\n",
       "      <td>-4.483765</td>\n",
       "      <td>-3.355975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11774</th>\n",
       "      <td>0.454611</td>\n",
       "      <td>0.070578</td>\n",
       "      <td>1029.274601</td>\n",
       "      <td>1519.231563</td>\n",
       "      <td>1922.927486</td>\n",
       "      <td>0.026553</td>\n",
       "      <td>-332.230408</td>\n",
       "      <td>202.603012</td>\n",
       "      <td>-0.181929</td>\n",
       "      <td>-2.146542</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.910435</td>\n",
       "      <td>-2.018668</td>\n",
       "      <td>-2.705635</td>\n",
       "      <td>-1.589172</td>\n",
       "      <td>-2.938737</td>\n",
       "      <td>-0.972690</td>\n",
       "      <td>-1.706672</td>\n",
       "      <td>-2.796168</td>\n",
       "      <td>2.171270</td>\n",
       "      <td>-1.660128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11775</th>\n",
       "      <td>0.374432</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>4063.645317</td>\n",
       "      <td>3558.261357</td>\n",
       "      <td>7299.133512</td>\n",
       "      <td>0.110278</td>\n",
       "      <td>-372.149109</td>\n",
       "      <td>92.670235</td>\n",
       "      <td>-29.082432</td>\n",
       "      <td>59.736637</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.552000</td>\n",
       "      <td>-6.628118</td>\n",
       "      <td>-3.827499</td>\n",
       "      <td>-7.287946</td>\n",
       "      <td>-2.899543</td>\n",
       "      <td>-11.508186</td>\n",
       "      <td>-1.296590</td>\n",
       "      <td>-14.325416</td>\n",
       "      <td>-4.405540</td>\n",
       "      <td>-15.869982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11776</th>\n",
       "      <td>0.410885</td>\n",
       "      <td>0.090499</td>\n",
       "      <td>1124.655596</td>\n",
       "      <td>1553.651133</td>\n",
       "      <td>2065.942806</td>\n",
       "      <td>0.031761</td>\n",
       "      <td>-328.062805</td>\n",
       "      <td>193.557526</td>\n",
       "      <td>6.779151</td>\n",
       "      <td>-1.304731</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.348275</td>\n",
       "      <td>-5.437202</td>\n",
       "      <td>-4.252508</td>\n",
       "      <td>-1.258683</td>\n",
       "      <td>-2.107233</td>\n",
       "      <td>-1.018154</td>\n",
       "      <td>-2.716950</td>\n",
       "      <td>-3.681598</td>\n",
       "      <td>3.811063</td>\n",
       "      <td>3.948419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11777</th>\n",
       "      <td>0.570581</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>2275.915286</td>\n",
       "      <td>3566.472303</td>\n",
       "      <td>4054.590126</td>\n",
       "      <td>0.052983</td>\n",
       "      <td>-398.812103</td>\n",
       "      <td>129.081482</td>\n",
       "      <td>3.654665</td>\n",
       "      <td>18.412062</td>\n",
       "      <td>...</td>\n",
       "      <td>4.769826</td>\n",
       "      <td>4.484940</td>\n",
       "      <td>3.916474</td>\n",
       "      <td>2.186594</td>\n",
       "      <td>1.218625</td>\n",
       "      <td>3.607651</td>\n",
       "      <td>4.629877</td>\n",
       "      <td>0.414103</td>\n",
       "      <td>5.229393</td>\n",
       "      <td>0.214607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11778 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chroma_stft       rms  spectral_centroid  spectral_bandwidth  \\\n",
       "0         0.338055  0.027948        2842.948867         4322.916759   \n",
       "1         0.443766  0.037838        2336.129597         3445.777044   \n",
       "2         0.302528  0.056578        2692.988386         2861.133180   \n",
       "3         0.319933  0.031504        2241.665382         3503.766175   \n",
       "4         0.420055  0.016158        2526.069123         3102.659519   \n",
       "...            ...       ...                ...                 ...   \n",
       "11773     0.435426  0.025303        2772.575031         2728.757601   \n",
       "11774     0.454611  0.070578        1029.274601         1519.231563   \n",
       "11775     0.374432  0.019063        4063.645317         3558.261357   \n",
       "11776     0.410885  0.090499        1124.655596         1553.651133   \n",
       "11777     0.570581  0.033022        2275.915286         3566.472303   \n",
       "\n",
       "           rolloff  zero_crossing_rate       mfcc1       mfcc2      mfcc3  \\\n",
       "0      6570.586186            0.041050 -462.169586   90.311272  19.073769   \n",
       "1      3764.949874            0.047730 -409.413422  120.348808  -7.161531   \n",
       "2      4716.610271            0.080342 -318.996033  120.490273 -24.625771   \n",
       "3      3798.641521            0.047180 -404.636749  136.320908   2.308172   \n",
       "4      5025.077899            0.051905 -410.497925  152.731400 -18.266771   \n",
       "...            ...                 ...         ...         ...        ...   \n",
       "11773  4998.670213            0.074323 -342.309753  144.490418 -79.272942   \n",
       "11774  1922.927486            0.026553 -332.230408  202.603012  -0.181929   \n",
       "11775  7299.133512            0.110278 -372.149109   92.670235 -29.082432   \n",
       "11776  2065.942806            0.031761 -328.062805  193.557526   6.779151   \n",
       "11777  4054.590126            0.052983 -398.812103  129.081482   3.654665   \n",
       "\n",
       "           mfcc4  ...     mfcc11     mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0      24.046888  ... -14.181895  -6.686564  0.902086 -7.251551 -1.198342   \n",
       "1       5.114784  ...   0.372541  -2.131157 -6.876417 -1.359395  0.326401   \n",
       "2      23.891073  ...  -3.099179  -5.853725 -3.724773 -6.627182 -5.117002   \n",
       "3      -3.907071  ...   1.513633  -1.898315 -2.046493 -7.176277 -3.293508   \n",
       "4      51.993462  ...  11.086248  -1.952340  0.810868  6.238493  6.555839   \n",
       "...          ...  ...        ...        ...       ...       ...       ...   \n",
       "11773   8.890874  ...  -2.950688 -17.982819 -7.831161 -1.127167 -7.669674   \n",
       "11774  -2.146542  ...  -2.910435  -2.018668 -2.705635 -1.589172 -2.938737   \n",
       "11775  59.736637  ... -17.552000  -6.628118 -3.827499 -7.287946 -2.899543   \n",
       "11776  -1.304731  ...  -7.348275  -5.437202 -4.252508 -1.258683 -2.107233   \n",
       "11777  18.412062  ...   4.769826   4.484940  3.916474  2.186594  1.218625   \n",
       "\n",
       "          mfcc16    mfcc17     mfcc18    mfcc19     mfcc20  \n",
       "0       4.747403 -4.986279   0.953935 -5.013138  -6.779060  \n",
       "1      -5.420016 -2.109968  -1.757634 -9.537907  -8.494421  \n",
       "2      -6.072106 -0.994653  -1.617120 -3.922354  -7.033001  \n",
       "3       4.209121  0.121835  -5.407063 -3.654926  -3.274857  \n",
       "4       7.535542  2.849219   2.616843 -1.793357  -5.060998  \n",
       "...          ...       ...        ...       ...        ...  \n",
       "11773  -0.653850 -8.037575  -2.671002 -4.483765  -3.355975  \n",
       "11774  -0.972690 -1.706672  -2.796168  2.171270  -1.660128  \n",
       "11775 -11.508186 -1.296590 -14.325416 -4.405540 -15.869982  \n",
       "11776  -1.018154 -2.716950  -3.681598  3.811063   3.948419  \n",
       "11777   3.607651  4.629877   0.414103  5.229393   0.214607  \n",
       "\n",
       "[11778 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert balanced csv into dataframe and seperate labels\n",
    "DATASET_PATH = \"/Users/connormaclachlan/Desktop/CS433_Project/KAGGLE/DATASET-balanced.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "data = df.iloc[:,:-1]\n",
    "labels = df.iloc[:,-1]\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "labels = labels.ravel()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into tensorflow dataset\n",
    "def convertToDataset(data, labels):\n",
    "    return tf.data.Dataset.zip(tf.data.Dataset.from_tensor_slices(data), tf.data.Dataset.from_tensor_slices(labels))\n",
    "\n",
    "# Process dataset\n",
    "def processData(data, labels):\n",
    "    data = tf.abs(data)\n",
    "    data = tf.expand_dims(data, axis=1)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.1, random_state=42)\n",
    "\n",
    "trainDataset = convertToDataset(X_train, y_train)\n",
    "testDataset = convertToDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.98713000e-01,  4.40390000e-02,  3.25821094e+03,  3.85114700e+03,\n",
       "         6.83959255e+03,  8.13260000e-02, -3.67204224e+02,  1.34100235e+02,\n",
       "         4.87364100e+00,  2.30041580e+01,  1.04666810e+01,  5.70958000e-01,\n",
       "        -2.51008210e+01,  5.90441100e+00, -4.06430200e+00,  2.09046700e+00,\n",
       "        -6.00957800e+00,  6.85579500e+00, -7.11480500e+00, -1.39212100e+00,\n",
       "        -5.72690200e+00,  3.22187300e+00, -3.89038000e-01, -3.91204000e-01,\n",
       "        -1.62757600e+00,  4.55036000e-01]),\n",
       " 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8244, 26)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "epochs = 100\n",
    "batch = 16\n",
    "prefetch = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "trainDataset = trainDataset.map(processData)\n",
    "trainDataset = trainDataset.cache()\n",
    "trainDataset = trainDataset.batch(batch)\n",
    "trainDataset = trainDataset.prefetch(prefetch)\n",
    "\n",
    "testDataset = testDataset.map(processData)\n",
    "testDataset = testDataset.cache()\n",
    "testDataset = testDataset.batch(batch)\n",
    "testDataset = testDataset.prefetch(prefetch)\n",
    "\n",
    "X_val = abs(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 5s 4ms/step - loss: 6.5657 - accuracy: 0.6630\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 2.4717 - accuracy: 0.7203\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 1.5537 - accuracy: 0.7464\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 0.9181 - accuracy: 0.7661\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.7855\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.6043 - accuracy: 0.7875\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4835 - accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4096 - accuracy: 0.8257\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3777 - accuracy: 0.8315\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8235\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8384\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3545 - accuracy: 0.8438\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8421\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8524\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3661 - accuracy: 0.8417\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8574\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8574\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8680\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8720\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8747\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8808\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.8834\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8890\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8893\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2798 - accuracy: 0.8845\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.8918\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.8916\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.8916\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.8968\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.8982\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.8981\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2562 - accuracy: 0.8980\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.8994\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8970\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2382 - accuracy: 0.9015\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.9020\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2374 - accuracy: 0.8994\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9019\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2338 - accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2307 - accuracy: 0.9050\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.9050\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.9047\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9053\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2209 - accuracy: 0.9124\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2272 - accuracy: 0.9087\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9064\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2219 - accuracy: 0.9085\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2180 - accuracy: 0.9129\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2239 - accuracy: 0.9081\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2281 - accuracy: 0.9096\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9049\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2276 - accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9108\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2138 - accuracy: 0.9138\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9136\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9146\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9190\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9189\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9195\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.9186\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1931 - accuracy: 0.9212\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9233\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9255\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9225\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9270\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9212\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.9273\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.9281\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9266\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9339\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9303\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9315\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.9312\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9349\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9349\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1701 - accuracy: 0.9309\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1607 - accuracy: 0.9383\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9392\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1592 - accuracy: 0.9391\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9362\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9387\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.9360\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1522 - accuracy: 0.9387\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9413\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9435\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9410\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9410\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1511 - accuracy: 0.9427\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1467 - accuracy: 0.9449\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1415 - accuracy: 0.9464\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9440\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9413\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9451\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9497\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.1504 - accuracy: 0.9410\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9506\n",
      "Test Accuracy: 0.950628936290741\n",
      "Test Loss: 0.13827264308929443\n"
     ]
    }
   ],
   "source": [
    "# Define the NN model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(516, activation='relu', input_shape=(26,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainDataset, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(testDataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fde6166cdc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model given validation data to make prediction\n",
    "predicted = model.predict(np.array(X_val))\n",
    "predicted = tf.squeeze(predicted)\n",
    "predicted = np.array([1 if x >= 0.5 else 0 for x in predicted])\n",
    "actual = np.array(y_val)\n",
    "conf_mat = confusion_matrix(actual, predicted)\n",
    "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "displ.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 95.19774011299435%\n"
     ]
    }
   ],
   "source": [
    "# Validation percentage\n",
    "predictPerc = (conf_mat[0][0]+conf_mat[1][1])/(conf_mat[0][0]+conf_mat[0][1]+conf_mat[1][0]+conf_mat[1][1])*100\n",
    "print(f\"Prediction Accuracy: {predictPerc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the Trained Model\n",
    "# model_file = \"DeepVoiceModel.pkl\"\n",
    "\n",
    "# with open(model_file, \"wb\") as file:\n",
    "#     pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
